<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="google-site-verification" content="TZE0rZyIqLl10trYu3BWBWa1Vmz6HFwhb2OcNEK4u-s" />
     <link rel="shortcut icon" href= /img/favicon.ico >
    <title>
        部落格
    </title>
    <meta name="description" content= 千里之行，始于足下 >
    <meta name="keywords" content= Blog >
    
<link rel="stylesheet" href="/libs/highlight/styles/monokai-sublime.css">

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="部落格" type="application/atom+xml">
</head>
<body id="bodyx">
    <div class="hd posts">
    <a href="/index.html"><i class="fa fa-home
 replay-btn" aria-hidden="true"></i></a>
    <div class="post-title">
        <p>
            项目问答及场景题扩展
        </p>
        <hr>
    </div>
    <div class="post-content">
        <h1 id="餐饮订购系统"><a href="#餐饮订购系统" class="headerlink" title="餐饮订购系统"></a>餐饮订购系统</h1><h3 id="介绍一下项目？里面有什么亮点难点？"><a href="#介绍一下项目？里面有什么亮点难点？" class="headerlink" title="介绍一下项目？里面有什么亮点难点？"></a>介绍一下项目？里面有什么亮点难点？</h3><p>我设计的是一个餐饮订购平台，其包括优惠券秒杀，用户登录，订单和库存管理等核心功能。在技术上，商品浏览和购物车模块通常请求量较大所以引入redis缓存加快请求响应，但引入缓存后考虑到可能会有缓存穿透的问题，所以加入布隆过滤器对非法数据进行过滤。用户在下单支付后，需要通知商家发货，所以使用了可以服务器主动推送的Websock协议，用户在下单后可能会未支付，需要对这些订单进行处理，这可以用延时队列来处理，考虑到RocketMQ提供了延时队列的功能，并且能保证消息的可靠传输，所以将消息投递到消息队列中，超时后被消费，修改订单状态。除此之外，在优惠券抢购中，在这种高并发的场景下，有两个难点需要被解决，一个是防止超卖，另外一个因为库存被预热到redis中，还需要考虑redis和DB的一致性。针对超卖的问题，其引发的原因主要是多个用户即多个线程同时读写库存，我使用的解决方案是lua脚本执行原子性读写。针对一致性的问题，也是使用RocketMQ的ACK和重传机制保证最终一致性。	</p>
<h2 id="登录模块"><a href="#登录模块" class="headerlink" title="登录模块"></a>登录模块</h2><h2 id="介绍一下登录流程？服务端是如何记住用户登录状态的？"><a href="#介绍一下登录流程？服务端是如何记住用户登录状态的？" class="headerlink" title="介绍一下登录流程？服务端是如何记住用户登录状态的？"></a>介绍一下登录流程？服务端是如何记住用户登录状态的？</h2><ul>
<li>登录流程基于JWT+拦截器的无状态鉴权体系：用户在提交账号密码后，服务端验证并生成Java web token 返回给客户端，客户端在后续请求中携带该Token，服务器通过拦截器解析Token并验证用户身份。</li>
</ul>
<h2 id="需要我再讲讲具体的签名验证过程吗？"><a href="#需要我再讲讲具体的签名验证过程吗？" class="headerlink" title="需要我再讲讲具体的签名验证过程吗？"></a>需要我再讲讲具体的签名验证过程吗？</h2><ul>
<li>JWT由三部分组成，分别是Header，payload，signature。首次生成signature时，对Header和payload和服务器密钥用算法加密生成签名。后续获取到token只要比对签名就可以判断内容是否被篡改。</li>
</ul>
<h3 id="为什么选择JWT而不是Session-Cookie机制？"><a href="#为什么选择JWT而不是Session-Cookie机制？" class="headerlink" title="为什么选择JWT而不是Session-Cookie机制？"></a>为什么选择JWT而不是Session-Cookie机制？</h3><p>首先第一个点JWT是无状态的，也就是说在服务器端不需要存储其他额外的信息，一个是减轻了服务器的负担，另一个就是Session-Cookie机制这种机制的话，对于在分布式场景下，需要多个服务器去同步同一个用户的信息，增加开销。第二个点就是JWT更加安全，对于跨域请求伪造，cookies在每次请求的时候都会自动发送，以至于被攻击，而jwt可以放在请求头的authorization里面，在需要时才发送</p>
<ul>
<li>jwt之所以不受同源限制是因为他需要显示添加到请求头，用户自定义控制风险。Cookies是发送请求时自带，为了避免CSRF需要同源限制</li>
</ul>
<h2 id="如果密钥泄露导致Token被伪造，如何快速发现和止损？"><a href="#如果密钥泄露导致Token被伪造，如何快速发现和止损？" class="headerlink" title="如果密钥泄露导致Token被伪造，如何快速发现和止损？"></a>如果密钥泄露导致Token被伪造，如何快速发现和止损？</h2><ul>
<li>可以采用双token方案，access token 用于鉴权并设立较短的时间， fresh token 设立较长的过期时间，服务端需记录其绑定的用户ID和设备信息，以便检测异常使用。当检测access token到期时，根据fresh token 重新生成新的access token。</li>
</ul>
<h3 id="拦截器和过滤器的底层原理"><a href="#拦截器和过滤器的底层原理" class="headerlink" title="拦截器和过滤器的底层原理"></a>拦截器和过滤器的底层原理</h3><ul>
<li>前端发送请求先到DispatcherServlet，然后到HandlerMapping匹配Hander，再到Hander Adaptor执行Handle，拦截器处理器执行前执行prehandle，视图渲染前执行postHandle,浏览器响应前执行afterComplete。拦截Spring管理的Controller请求，适用认证与权限验证。执行顺序Filter前置-&gt;Interceptor-&gt;Filter后置</li>
<li>过滤器底层是执行回调函数，处理粒度是在HTTP请求和响应层面，适用全局编码处理。拦截器体现AOP思想，即对web请求应用同一组方法，分别在处理器执行前执行prehandle，视图渲染前执行postHandle,浏览器响应前执行afterComplete。拦截Spring管理的Controller请求，适用认证与权限验证。执行顺序Filter前置-&gt;Interceptor-&gt;Filter后置</li>
<li>（Spring MVC）拦截器执行顺序 查找处理器-&gt;prehandle-&gt;处理器执行-&gt;postHandle-&gt;视图渲染-&gt;afterComplete-&gt;浏览器响应</li>
</ul>
<h3 id="为什么使用ThreadLocal？"><a href="#为什么使用ThreadLocal？" class="headerlink" title="为什么使用ThreadLocal？"></a>为什么使用ThreadLocal？</h3><ul>
<li>一个是为保证了并发安全，在有多个用户登录时，意味着有多个线程访问，使用一个变量例如用户id会出现竞态条件，利用ThreadLocal的线程隔离性，为每个线程分配独立的变量副本，保证线程安全。第二点因为用户登录和订单服务放在同一个服务实例中，如果显示传参太复杂，通过ThreadLocal可以隐式传参，简化代码逻辑。</li>
</ul>
<h3 id="如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？"><a href="#如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？" class="headerlink" title="如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？"></a>如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？</h3><ul>
<li>手动处理&#x2F;定时处理&#x2F;任务处理完后遍历处理&#x2F;需要注意一是，如果存储在 <code>ThreadLocal</code> 中的对象是可变的（例如一个可变集合），仍然可能存在线程安全问题&#x2F;如果任务之间不能共享 <code>ThreadLocal</code> 数据，可以考虑为每个任务分配独立的线程&#x2F;需要任务之间共享 <code>ThreadLocal</code> 数据，可以使用 <code>InheritableThreadLocal</code></li>
</ul>
<h2 id="商品浏览模块-购物车模块"><a href="#商品浏览模块-购物车模块" class="headerlink" title="商品浏览模块&#x2F;购物车模块"></a>商品浏览模块&#x2F;购物车模块</h2><h3 id="对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？"><a href="#对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？" class="headerlink" title="对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？"></a>对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？</h3><ul>
<li>在项目中，为了防止恶意请求访问不存在的商品ID，在redis缓存层之前加了一层布隆过滤器，用于快速判断商品ID是否存在。我是设定项目目前有1w个商品，商品id是64位长整型，误判率设置为0.1%（设置为0.1主要权衡性能和准确性，如果误判率设置太小，意味这着需要更大的位数组，对于电商项目来说，更注重性能），通过公式计算，需要大概18KB的位数组和10个哈希函数。</li>
<li>1000w商品id，误判率0.1%，位数组为17MB，10个哈希函数</li>
</ul>
<h3 id="如果商品数据每日新增百万级，如何动态更新布隆过滤器？"><a href="#如果商品数据每日新增百万级，如何动态更新布隆过滤器？" class="headerlink" title="如果商品数据每日新增百万级，如何动态更新布隆过滤器？"></a>如果商品数据每日新增百万级，如何动态更新布隆过滤器？</h3><ul>
<li>首先我会考虑更新的时机，1个是考虑到白天会有大量用户访问业务，如果这时候更新布隆过滤器会导致短时间的过滤服务停止，会产生缓存穿透问题，所以可以根据访问记录，选择访问数量少的时段，例如定期在凌晨更新，第二个点考虑到更新布隆器时会有过滤服务停止时机，考虑增加一个备份的布隆过滤器，在需要更换的时候直接替换，这时候就是用空间来换时间。第三个点的话可以考虑将布隆过滤器分片，这样每次更新的话，这更新一部分数据的过滤器。第四点的话，也是牺牲性能，考虑使用计数型布隆过滤器。</li>
</ul>
<h3 id="在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？"><a href="#在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？" class="headerlink" title="在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？"></a>在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？</h3><ul>
<li>对于一些商品的基本信息，例如商品名，商品口味等不需要频繁变动的，使用了String类型执行存储，key为商品id，value为JSON字符串。对于购物车这种需要频繁访问和变动的则用Hash来存储，方便随时获取某一字段的value。对比Memcache，提供丰富的数据结构，事务、持久化机制等</li>
</ul>
<h3 id="你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？"><a href="#你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？" class="headerlink" title="你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？"></a>你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？</h3><ul>
<li>热点商品可以通过商品的访问次数，或者加入到购物车的次数来识别。具体来说，如果是单体项目，可以直接用本地内存例如直接用HashMap去存储商品次数，在分布式环境下，可以使用redis存储。</li>
<li>一个是定期去判断该商品是否为热点商品，如果是就更新过期时间，第二点就是并发控制，在突然失效的时候，控制只让一个线程访问数据，更新缓存。 第三点就是，服务降级嘛，拒绝一些请求，防止系统奔溃。</li>
</ul>
<h3 id="如何保证redis和数据库的一致性？"><a href="#如何保证redis和数据库的一致性？" class="headerlink" title="如何保证redis和数据库的一致性？"></a>如何保证redis和数据库的一致性？</h3><ul>
<li>对于普通商品详情页，是一种读多写少的场景，对于数据一致性要求不是很严格。所以我使用的是旁路缓存，写入数据库后删缓存，虽然它不能保证强一致性，但是它通过过期时间实现最终一致性。对比更新缓存复杂性增加，做更新失败的判断逻辑，另外每次都要将数据放到redis更新。对于延迟双删：需要额外的定时任务或消息队列。当然对于读写穿透，也就是让缓存层同步数据库以保证强一致性，但这种方法给缓存层带来更大的压力的同时，同步意味着需要牺牲性能，所以没采用这种方法。对于热点数据，例如优惠券的库存，我的目标是只要保证最终一致性就行，所以采用异步更新数据库的方式，以提升系统性能。如果要保证强一致的话就要牺牲性能，通过同步的方式保证一致性。</li>
</ul>
<h3 id="如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？"><a href="#如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？" class="headerlink" title="如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？"></a>如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？</h3><ul>
<li>首先缓存删除失败通常可能是网络IO或者redis服务器繁忙的问题，那么可以使用重试机制，根据网络条件设置重试间隔或者避免频繁重试的话可以使用指数退避。当然对于商品详情页来说只要实现最终一致的话，依赖redis的过期时间即可保证最终一致性。在异步更新数据库的时候失败，也可以使用重试的机制，当到达最大重试次数，会投入死信队列，设立定时任务重新将消息重新投递。</li>
</ul>
<h3 id="对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？"><a href="#对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？" class="headerlink" title="对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？"></a>对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？</h3><ul>
<li>首先购物车模块用的是Hash数据结构，一个用户一个商品id为64位整数，8个字节。商品数量设计为4个字节，属性+价格大概20个字节，redis自身Hash额外开销大概在70字节，平均下来一个商品需要100字节。如果每个用户为最大为100个商品，那么就分配10kB的内存。</li>
</ul>
<h3 id="购物车数据用Redis-Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？"><a href="#购物车数据用Redis-Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？" class="headerlink" title="购物车数据用Redis Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？"></a>购物车数据用Redis Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？</h3><ul>
<li>一个Hash存大量的field意味着，Hash在扩容的时候会按照2的幂次方扩容，那么很容易产生内存碎片。可以考虑对商品按id&#x2F;热点id进行分片。清空购物车保证与DB原子性，清空购物车通常不需要强一致性，可以使用消息队列解耦，用通过重试机制保证最终一致性。如果需要强一致性的话可以使用2PC分布式事务，保证数据库和缓存强一致性。</li>
</ul>
<h3 id="多端（Web-APP）同时修改购物车，如何保证数据正确性？"><a href="#多端（Web-APP）同时修改购物车，如何保证数据正确性？" class="headerlink" title="多端（Web&#x2F;APP）同时修改购物车，如何保证数据正确性？"></a>多端（Web&#x2F;APP）同时修改购物车，如何保证数据正确性？</h3><ul>
<li>在这种并发不高的情况，可以使用redis的watch命令实现乐观锁，watch+key ，如果key对应的value在被更改前被其他线程更改了，则抛出异常执行重试逻辑。当然如果是高并发的场景，可以考虑使用分布式锁，对用户id进行加锁。</li>
</ul>
<h3 id="购物车数据需要持久化吗？何时同步到DB？"><a href="#购物车数据需要持久化吗？何时同步到DB？" class="headerlink" title="购物车数据需要持久化吗？何时同步到DB？"></a>购物车数据需要持久化吗？何时同步到DB？</h3><ul>
<li>对于订餐场景，我考虑的只是作为一直临时性的存储，只存放在redis里面，会话结束后删除。如果希望会话结束之后还存在的话，可以根据实时性需求和性能的取舍，通过实时同步或者批量同步或者异步到数据库</li>
</ul>
<h3 id="你提到在商品浏览和购物车模块中使用了-Redis-缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？"><a href="#你提到在商品浏览和购物车模块中使用了-Redis-缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？" class="headerlink" title="你提到在商品浏览和购物车模块中使用了 Redis 缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？"></a>你提到在商品浏览和购物车模块中使用了 Redis 缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？</h3><ul>
<li>首先在电商的场景下，基本商品信息通常读多写少，所以我为他们设立了1小时的过期时间。对于商品详情（当然如果商品量比较大redis内存有限，可以根据商品的访问频率来设定过期时间，热门商品可以设立更长的过期时间），对于购物车来说，写操作比较频繁，过期时间可以更短。那么处理过期的商品信息有几种方案，一个是为每个key开启定时器，则直接删除对应的key，或者使用延时队列处理，这两张方法精确度比较高，但是随着key的增多，定时器的开销和队列的开销会上升。通过redis懒删除+定期随机抽样删除的方式处理过期商品，通过设立定期抽样删除的频率做性能和内存回收的权衡嘛，懒删除的话可以保证过期商品可以被正确处理</li>
</ul>
<h3 id="你的-Redis-实例是如何配置淘汰策略的？是使用默认的-LRU-策略，还是选择了其他策略？为什么？"><a href="#你的-Redis-实例是如何配置淘汰策略的？是使用默认的-LRU-策略，还是选择了其他策略？为什么？" class="headerlink" title="你的 Redis 实例是如何配置淘汰策略的？是使用默认的 LRU 策略，还是选择了其他策略？为什么？"></a>你的 Redis 实例是如何配置淘汰策略的？是使用默认的 LRU 策略，还是选择了其他策略？为什么？</h3><ul>
<li>对于这个系统来说，对于商品浏览和购物车来说是，是典型的热点数据频繁访问，LRU也就是最近最少使用访问淘汰策略，可以更好识别出热门商品数据，其他淘汰策略例如随机淘汰，适合访问频率比较均匀的。LFU虽然长期来看也能鉴别出热门数据，但是它的实现是要为每个key维护一个计数器以统计频率，可能会有开销。</li>
</ul>
<h3 id="热点-Key-问题解决方案"><a href="#热点-Key-问题解决方案" class="headerlink" title="热点 Key 问题解决方案"></a>热点 Key 问题解决方案</h3><ul>
<li>本地缓存，热点分片（分片算法），提前预热</li>
</ul>
<h3 id="Redis-大key会有什么问题？解决方案？"><a href="#Redis-大key会有什么问题？解决方案？" class="headerlink" title="Redis 大key会有什么问题？解决方案？"></a>Redis 大key会有什么问题？解决方案？</h3><ul>
<li>删除时单线程阻塞，持久化开销大：RDB AOF，网络IO,主从复制&#x2F;业务分片，按字段切分</li>
</ul>
<h3 id="订单模块"><a href="#订单模块" class="headerlink" title="订单模块"></a>订单模块</h3><h3 id="为什么使用Websock？"><a href="#为什么使用Websock？" class="headerlink" title="为什么使用Websock？"></a>为什么使用Websock？</h3><ul>
<li>首先相比于传统的HTTP请求（即使是短轮询或者长轮询），WebSocket提供更低的延迟，因为它本身就是建立了持久连接。其次它允许服务端主动向客户端推送消息。所以比较适合订餐系统中及时通知商家的场景。</li>
</ul>
<h3 id="WebSocket建立过程"><a href="#WebSocket建立过程" class="headerlink" title="WebSocket建立过程"></a>WebSocket建立过程</h3><ul>
<li>首先客户端向服务端发送一个Http请求，里面包含websocket的路径，upgrade字段设置为websocket。</li>
</ul>
<h3 id="如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？"><a href="#如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？" class="headerlink" title="如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？"></a>如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？</h3><ul>
<li>首先websock建立的是持久连接，并且使用了心跳机制，通过定期给客户端发送ping检测网络断连，断联后可以考虑使用指数退避算法避免频繁重连。如果商户离线，未处理的订单通知可以先放进消息队列，等到重连后客户端再重新消费。或者将未处理订单记录放进表中，商户上线后服务端查询订单未读通知，重新推送，再或者存入Redis Sorted Set（按时间排序），按时间取出消息重新推送。可以通过使用Nginx将根据商户id，将websock连接分配到不同服务实例。</li>
</ul>
<h3 id="WebSocket-性能有什么问题？WebSocket-服务如何横向扩展以支持10万级商户同时在线？"><a href="#WebSocket-性能有什么问题？WebSocket-服务如何横向扩展以支持10万级商户同时在线？" class="headerlink" title="WebSocket 性能有什么问题？WebSocket 服务如何横向扩展以支持10万级商户同时在线？"></a>WebSocket 性能有什么问题？WebSocket 服务如何横向扩展以支持10万级商户同时在线？</h3><ul>
<li>连接开销大，每个websocket连接都要占用服务器资源，并发量大的时候会造成压力。另外为了保持连接活跃并检测断线情况，通常需要定期发送心跳包，增加服务器负担。可以水平拓展多个websocket实例，使用反向代理服务器来分发 WebSocket 连接到多个后端服务器实例上，确保每个服务器处理的连接数在一个可接受的范围内。</li>
</ul>
<h3 id="如何防止网络抖动导致消息丢失？"><a href="#如何防止网络抖动导致消息丢失？" class="headerlink" title="如何防止网络抖动导致消息丢失？"></a>如何防止网络抖动导致消息丢失？</h3><ul>
<li>为每个消息生成唯一的ID，加入确认机制，如果没收到ack就重传。对于重要消息可以通过消息队列来传输，因为RocketMQ或kafka会提供可靠性保障。</li>
</ul>
<h3 id="为什么使用RocketMQ处理超时订单？"><a href="#为什么使用RocketMQ处理超时订单？" class="headerlink" title="为什么使用RocketMQ处理超时订单？"></a>为什么使用RocketMQ处理超时订单？</h3><ul>
<li>首先它支持延迟消息，生产者发送带延迟消息的订单，消息在指定时间之后才允许被消费。第二个就是对比直接使用数据库定时任务，去查询超时订单，可以减轻数据库压力，也就是说在高并发场景下效果更好。最后就是，它提供可靠的消息传递，通过重试机制，和死信队列保证最终一致性。当然使用Redis的Zset也可以实现延时队列的功能，但是每次需要轮询Zset触发处理到期任务，在数据量较大的适合性能产生瓶颈</li>
</ul>
<h3 id="超时订单技术选型"><a href="#超时订单技术选型" class="headerlink" title="超时订单技术选型"></a>超时订单技术选型</h3><ul>
<li>JAVA自带的DelayQueue优先队列，轮询队列头部，牺牲内存，不适合分布式处理。RocketMQ每个订单对应一条消息，且不会马上消费，给MQ带来很大的存储成本，不适合大量订单场景。定时任务扫描，周期性扫描数据库，随着订单量增大，数据库扫描压力增大。Redis的Zset的key为订单类型：score为时间戳+超时时间 memeber为订单号，高并发时候会获取同一个订单号。</li>
</ul>
<h3 id="使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？"><a href="#使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？" class="headerlink" title="使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？"></a>使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？</h3><ul>
<li>增加分区和消费者实例，调整消费线程数，批量消费减少IO</li>
</ul>
<h3 id="RocketMQ-只支持固定延迟级别（如1s-5s-10s），如何实现自定义延迟（如精确30分钟）？"><a href="#RocketMQ-只支持固定延迟级别（如1s-5s-10s），如何实现自定义延迟（如精确30分钟）？" class="headerlink" title="RocketMQ 只支持固定延迟级别（如1s, 5s, 10s），如何实现自定义延迟（如精确30分钟）？"></a>RocketMQ 只支持固定延迟级别（如1s, 5s, 10s），如何实现自定义延迟（如精确30分钟）？</h3><ul>
<li>第一种方案可以考虑，先用最合适的固定延迟级别，然后到期消费后，在消费端的逻辑做判断，如果没到时可以考虑先将消息存储，定时任务再触发去消费该消息，可能考虑消费者宕机消息丢失情况。第二种就在消费者端做判断，重新将消息发回RocketMQ，做延迟队列的组合</li>
</ul>
<h3 id="延时队列底层原理"><a href="#延时队列底层原理" class="headerlink" title="延时队列底层原理"></a>延时队列底层原理</h3><ul>
<li>根据延时级别将消息存储到内部定时Topic-&gt;时间轮算法：Broker启动，为每个延迟级别创建一个时间轮槽位，组成环形结构。每个槽位对应一个定时任务队列（消息）-&gt;消息进入定时主题时解析延时级别 计算存入目标槽位。broker启动后台线程池（驱动，消息到期检测，投递），每秒驱动时间轮遍历槽位消息重定向到目标Topic用于被消费</li>
</ul>
<h3 id="介绍一下项目的订单模型？"><a href="#介绍一下项目的订单模型？" class="headerlink" title="介绍一下项目的订单模型？"></a>介绍一下项目的订单模型？</h3><ul>
<li>首先订单表包括订单的基本信息订单ID，用户ID，总金额，订单状态，创建时间等。还有订单详情表，包括订单ID,收货地址，商品详情等。订单也关联实体有，例如用户，商品，库存，支付记录等。另外，订单从创建到结束包括多个状态，例如待支付，超时，已支付，已退款。</li>
</ul>
<h3 id="在大量订单情况下，有什么解决方案？"><a href="#在大量订单情况下，有什么解决方案？" class="headerlink" title="在大量订单情况下，有什么解决方案？"></a>在大量订单情况下，有什么解决方案？</h3><ul>
<li>在高并发请求的场景下，将数据库分片，分散请求的流量，分片键可以选择订单ID，用户ID或者按照创建时间。对于单表较大导致IO次数过多的情况下，考虑使用，按冷热字段分表例如订单基本信息表和详情表。或者根据订单id+用户id分表。分片算法在没有频繁变动分片数量时候可以用简单的哈希取模，或者维护一个映射表，在频繁变动的情况使用一致性哈希。</li>
</ul>
<h2 id="优惠券模块"><a href="#优惠券模块" class="headerlink" title="优惠券模块"></a>优惠券模块</h2><h3 id="讲讲优惠券抢券模块流程，和数据库表设置"><a href="#讲讲优惠券抢券模块流程，和数据库表设置" class="headerlink" title="讲讲优惠券抢券模块流程，和数据库表设置"></a>讲讲优惠券抢券模块流程，和数据库表设置</h3><ul>
<li>用户选择优惠券后下单，前端发送用户id和优惠券id，服务端进行幂等校验，使用Redis Set记录用户是否已经领取过优惠券（用户id和优惠券id），为了避免对数据库进行频繁写入造成性能瓶颈，扣除redis中的预热库存，使用RocktMQ进行异步批量提交，DB消费消息，更新用户优惠券表和优惠券库存表。</li>
<li>数据库表主要设计了三个表，一个是优惠券基本信息表，一个用户领取表，记录用户和优惠券的关系，一个是优惠券库存表记录优惠券库存</li>
</ul>
<h3 id="幂等性的实现方案"><a href="#幂等性的实现方案" class="headerlink" title="幂等性的实现方案"></a>幂等性的实现方案</h3><ul>
<li>set的key为券id，value为user id。命令SADD key member ，若成功添加证明无重复元素，返回1，若返回0则是有重复元素。</li>
<li>数据库层面：券id+user id作为唯一索引</li>
<li>用户进入订单确认页的时候生成一个token，并返回给客户端，客户端后续携带token，若存在token则第一次访问，执行服务后删除token</li>
</ul>
<h3 id="预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？"><a href="#预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？" class="headerlink" title="预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？"></a>预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？</h3><ul>
<li>利用RocketMQ持久化来保证系统崩溃了也能被恢复，消费失败时尝试重试策略，到达重试次数移入死信队列，进行人工处理。为了避免不重复消费，可以给消息添加唯一标识符，消费时判断，或者在数据库中添加字段标记是否成功处理。如果只要求最终一致性，可以启用一个定时任务，检查redis中库存和数据库实际库存一致，做补偿。</li>
<li>如果要回滚redis，首先可以使用数据库事务+redis事务的方法，先开启数据库事务如果数据库更新成功，再提交redis事务，如果redis扣除成功则提交事务否则回滚数据库事务。第二点就是redis写入成功意味着redis IO是正常的，可以将redis扣除库存的日志写入redis中，如果数据库更新成功就删除日志，否则根据日志回滚。</li>
</ul>
<h3 id="为什么选择Lua脚本而不是Redis事务（MULTI-EXEC）？"><a href="#为什么选择Lua脚本而不是Redis事务（MULTI-EXEC）？" class="headerlink" title="为什么选择Lua脚本而不是Redis事务（MULTI&#x2F;EXEC）？"></a>为什么选择Lua脚本而不是Redis事务（MULTI&#x2F;EXEC）？</h3><ul>
<li>Lua脚本将几条命令封装为一条原子命令执行，期间不可中断。如果使用地是Redis事务，主要用的是Multi&#x2F;exec，在exec之前其他客户端也可以发送命令，导致事务失败。第二就是减少了网络传输地次数，lua脚本是一条命令只要一次传输，redis事务要多次传输</li>
</ul>
<h3 id="“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？"><a href="#“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？" class="headerlink" title="“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？"></a>“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？</h3><ul>
<li>为了避免每次库存扣减都从第一个分片开始，造成单实例压力过大。维护一个分片ID的数组，和一个整型计数器。当有一个新的请求时，打乱分片id数组，使得每次请求分片按不同顺序分片扣除库存。可以用一个表记录每个分片剩余量，当剩余量为0时跳过。对比哈希取模去进行负载均衡的话，其扩展性比较差，在添加实例时，需要按新的数量取模，重新分布库存。</li>
</ul>
<h3 id="讲讲超卖产生的原因以及如何防止超卖？"><a href="#讲讲超卖产生的原因以及如何防止超卖？" class="headerlink" title="讲讲超卖产生的原因以及如何防止超卖？"></a>讲讲超卖产生的原因以及如何防止超卖？</h3><ul>
<li>超卖的主要原因是判断库存数量和扣除库存这两步不是原子的，当多个线程修改同一个优惠券库存时，由于同一个线程两次读数据不一致，导致库存多扣。有几种思路可以解决，如果是直接访问数据库去扣除库存，在单服务实例时，在业务层可以使用JVM锁例如Synchronized或者ReentransLock，如果是多服务实例时JVM锁失效，可以考虑使用redis分布式锁。在数据库层面，可以使用互斥锁，例如update语句或者for update，或者可以使用乐观锁的思想，通过CAS去保证并发安全。另外本项目采取的思路是，由于考虑到在抢券时并发激烈，先将库存预热到redis里，将判断库存和扣减库存两个命令写成lua脚本，利用redis命令执行是单线程的，将lua脚本作为一条命令放入redis执行，以保证判断库存和扣减库存是原子性的。 扣除完后将消息投递到消息队列中，数据库服务异步消费。这种方法既保证线程安全同时减轻数据库负担。</li>
</ul>
<h3 id="讲讲分布式锁"><a href="#讲讲分布式锁" class="headerlink" title="讲讲分布式锁"></a>讲讲分布式锁</h3><ul>
<li>使用setnx key value EX time 保证设置键和过期时间为原子性执行。防止线程A获取锁后实例挂了，没释放，此时又没设置过期时间。–如果在执行过程中，锁过期了，导致其他线程获得锁同时访问资源导致操作错误。所以使用锁续期，开启一个线程每个5秒查看锁是否存在，如果存在则继续续期为10s。当然如果，B已经获取了分布式锁，A有可能会误删锁，所以可以为每个线程上锁时生成一个唯一标识写入value中，在删除锁时先匹配标识，一致才可以删除，这个过程也需要原子性，所以也要通过lua脚本。—-在Redis主从一致环境下，如果主还未同步锁给从实例GG，此时会有AB线程都会获得锁的情况，导致资源被并行访问导致脏数据。可以使用RedLock算法，即线程锁时，需要将锁写入一定数量的从节点从保证上锁成功，以牺牲性能换取高可靠。</li>
</ul>
<h1 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h1><h3 id="介绍一下工作流程"><a href="#介绍一下工作流程" class="headerlink" title="介绍一下工作流程"></a>介绍一下工作流程</h3><ul>
<li>服务端先将接口服务的全限定名和IP地址+端口注册到注册中心，客户端通过接口名调用服务，动态代理拦截接口方法，根据服务接口的全限定名获取方法地址，底层基于TCP，添加版本类型，包类型，序列化类型，和数据长度作为包头，定义实现了序列化接口的RPC发送类，里面定义了调用的方法名和参数类型以及具体参数。将RPC发送类序列化后，根据地址传输到服务端。服务端解析包头，根据数据长度获取包长，根据包类型和序列化方式，反序列化获取需要调用的方法名，以及所用的参数。调用服务获得结果后，按同样的方法返回给客户端。</li>
</ul>
<h3 id="为什么选择Netty而不是传统BIO或直接使用Java-NIO？如何优化Netty的线程模型以支撑10万级QPS？"><a href="#为什么选择Netty而不是传统BIO或直接使用Java-NIO？如何优化Netty的线程模型以支撑10万级QPS？" class="headerlink" title="为什么选择Netty而不是传统BIO或直接使用Java NIO？如何优化Netty的线程模型以支撑10万级QPS？"></a>为什么选择Netty而不是传统BIO或直接使用Java NIO？如何优化Netty的线程模型以支撑10万级QPS？</h3><ul>
<li>首先它相比于传统的BIO，在进行IO连接的时候，使用的是事件驱动的方法，只用更少的线程去支撑海量的连接，避免资源耗尽。另外对比用JAVA NIO的话，java NIO需要自己去创建seletor，注册事件，netty封装了底层这些细节，提供更高层次的API</li>
</ul>
<h3 id="介绍BIO-NIO-JAVA-NIO"><a href="#介绍BIO-NIO-JAVA-NIO" class="headerlink" title="介绍BIO NIO JAVA NIO"></a>介绍BIO NIO JAVA NIO</h3><ul>
<li>BIO就说BlockingIO，也就是阻塞IO，也就是说服务端创建一个线程处理客户端的读写连接时，当数据还没到来，线程会被阻塞。随着连接数增多，也就是工作线程增多，大量线程的阻塞导致占用大量系统资源。而JAVA NIO则是New IO，本质上是使用了IO多路复用的方法处理多个连接。多路则是指多个连接，复用则是指用一个或者少量的线程去处理这些连接。具体来说，IO多路复用用三种机制，分别是（select，poll和epoll），对于select来说，对每个连接都维护一个文件描述符fd，将fd的事件例如连接、读、写就绪注册到select上，执行select的时候阻塞等待fd上事件的到来，内核态轮询fd事件到来时将修改标志位并返回fd的集合，用户态轮询所有fd，查询事件发生的fd进行处理，以实现单个线程监听多个连接的事件实现多路复用。select有个弊端就是监控的fd有限，poll则是通过动态数组存储fd以扩展可用的fd数量。而epoll则是将fd构成了一棵红黑树，当有事件来临时则，通过触发的方式将fd加入到一个双向链表中，用户只要进行一次系统调用则可获取触发事件的fd列表，不需要对所有fd进行轮询。</li>
</ul>
<h3 id="Reactor模型"><a href="#Reactor模型" class="headerlink" title="Reactor模型"></a>Reactor模型</h3><ul>
<li>处理一次IO为三部分：连接处理（注册事件–accept）、IO读写（Handle）、业务处理（Handle）—-单Reactor是指，连接、IO处理，业务处理都用同一个线程—一旦阻塞不能处理后续节点连接—-6.0之前redis是这个模型。<strong>多线程 Reactor 模型</strong>：主线程处理连接，以及读写，子线程池（此时非阻塞体现在如果channel无读事件，会立刻返回以实现线程池的线程复用）处理业务，发挥多核优势，但IO读写还是用一个线程导致其他读写阻塞。主从Reactor多线程模型是指，连接和IO分别用不同线程处理，主为处理连接注册事件（accept），（线程池）创建线程处理IO读写，业务处理时用多个线程（线程池）。</li>
</ul>
<h3 id="Netty整体工作机制"><a href="#Netty整体工作机制" class="headerlink" title="Netty整体工作机制"></a>Netty整体工作机制</h3><ul>
<li>网络通信层 客户端服务端启动，监听指定端口—事件调度器主从多线程模型 Boss，Worker—服务编排层，即work处理使用处理链（业务是否多线程自己处理）</li>
</ul>
<h3 id="Netty性能好在哪里？"><a href="#Netty性能好在哪里？" class="headerlink" title="Netty性能好在哪里？"></a>Netty性能好在哪里？</h3><ul>
<li>IO连接使用多Reactor模型、使用零拷贝机制，即通过api直接读写直接内存，避免拷贝进堆内存，提供多种序列化方式，包括性能告得protobuf</li>
</ul>
<h3 id="你是如何解决粘包拆包的？Netty是如何实现的"><a href="#你是如何解决粘包拆包的？Netty是如何实现的" class="headerlink" title="你是如何解决粘包拆包的？Netty是如何实现的"></a>你是如何解决粘包拆包的？Netty是如何实现的</h3><ul>
<li>因为我底层用的是TCP，TCP是基于字节流的，而且保证有序到达。所以我通过在包头前面添加一个包长字段，解析出长度后，每次获取包长的字节数，以解决粘包拆包问题。Netty是封装了3种解决粘包的方案，一种是固定消息长度，每次收发固定长度的消息。第二种是以特定分隔符结尾，第三种应该是跟我这个思想一样，标明固定长度。</li>
</ul>
<h3 id="为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？"><a href="#为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？" class="headerlink" title="为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？"></a>为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？</h3><ul>
<li>一个是兼容不同的编程语言和平台，二是根据需求来指定序列化方式，例如JSON便于阅读，适用于开发阶段。Protobuf是基于二进制的，性能更好。首先在抽象层可以定义一个通用的接口，包括序列化方法和反序列化方法。其次可以使用工厂模式来获取序列化编码器，注册的时候直接在工厂内部将序列化代码和编码器放入一个Map中，每次使用序列化代码调用工厂即可。</li>
</ul>
<h3 id="Protobuf和JSON的性能差异有多大？介绍一下Protobuf"><a href="#Protobuf和JSON的性能差异有多大？介绍一下Protobuf" class="headerlink" title="Protobuf和JSON的性能差异有多大？介绍一下Protobuf"></a>Protobuf和JSON的性能差异有多大？介绍一下Protobuf</h3><ul>
<li>Protobuf使用二进制格式而不是文本格式，减少了传输的体积，大概快3-10倍。通过定义<code>.proto</code>文件来描述数据结构，Protobuf能够自动生成对应多种编程语言的源代码。在反序列化的时候，根据<code>.proto</code>文件指定的结构还原对象。</li>
</ul>
<h3 id="为什么选择JDK动态代理而非CGLIB？"><a href="#为什么选择JDK动态代理而非CGLIB？" class="headerlink" title="为什么选择JDK动态代理而非CGLIB？"></a>为什么选择JDK动态代理而非CGLIB？</h3><ul>
<li>客户端使用RPC调用服务的时候，是调用了服务接口，而JDK动态代理适用实现接口的类，在这个场景下性能比CGLIB好，因为前者通过反射调用目标方法开销小，CGLIB通过字节码操作技术生成目标类的一个子类来实现代理功能。</li>
</ul>
<h3 id="如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？"><a href="#如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？" class="headerlink" title="如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？"></a>如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？</h3><ul>
<li>主要用两点，一个是心跳机制：客户端定期向服务注册中心发送心跳包，以表明其仍然存活。如果服务中心一段时间没收到，则认为服务不可用，从列表删除。第二个是重试机制，在服务调用失败的时候，能够快速选择其他好的服务或者重试。Nacos内部实现了高效的缓存一致性协议，确保客户端缓存和服务端的数据一致性。另外Nacos主动推送自己的最新服务给客户端。Zookeeper强调强一致性，适用强一致性场景，牺牲了性能。Nacos更专注于服务注册，提供合适的API，例如服务注册，健康检查等功能。</li>
</ul>
<h3 id="如何设计一个注册中心？"><a href="#如何设计一个注册中心？" class="headerlink" title="如何设计一个注册中心？"></a>如何设计一个注册中心？</h3><ul>
<li>服务注册与发现（Map），健康检查(心跳机制)，负载均衡，高可用（集群，一致性算法），可拓展</li>
</ul>
<h3 id="如果某个服务节点响应时间突然变长，如何动态调整权重？"><a href="#如果某个服务节点响应时间突然变长，如何动态调整权重？" class="headerlink" title="如果某个服务节点响应时间突然变长，如何动态调整权重？"></a>如果某个服务节点响应时间突然变长，如何动态调整权重？</h3><ul>
<li>根据ping的响应时间调整权重。</li>
</ul>
<h3 id="讲讲Nacos的Raft"><a href="#讲讲Nacos的Raft" class="headerlink" title="讲讲Nacos的Raft"></a>讲讲Nacos的Raft</h3><ul>
<li>raft有三种角色，一个是Leader，follower和Condidate，首先是选举，Leader宕机后或到达任期之后，follower按一定随机时间生成Condiate，通过请求投票，当获取超半数之后升级为leader。主从是读写分离，为了保证一致性，写操作统一写入leader，leader同步日志到follower，超过一定数量后给客户端响应。</li>
</ul>
<h3 id="如何实现RPC调用超时和重试机制？"><a href="#如何实现RPC调用超时和重试机制？" class="headerlink" title="如何实现RPC调用超时和重试机制？"></a>如何实现RPC调用超时和重试机制？</h3><ul>
<li>调用时设计超时时间，超时指数退避重试。幂等性，唯一标识符。</li>
</ul>
<h3 id="如果有个系统要应用到你的RPC框架，需要做哪些事情？"><a href="#如果有个系统要应用到你的RPC框架，需要做哪些事情？" class="headerlink" title="如果有个系统要应用到你的RPC框架，需要做哪些事情？"></a>如果有个系统要应用到你的RPC框架，需要做哪些事情？</h3><h3 id="性能瓶颈在哪里？"><a href="#性能瓶颈在哪里？" class="headerlink" title="性能瓶颈在哪里？"></a>性能瓶颈在哪里？</h3><ul>
<li>首先是网络IO–可以通过使用合适的序列化方式例如protobuf减少数据量，或者批量调用减少网络次数。第二个是序列化，选用高效的序列化方法也很重要。另外在客户端，当频繁调用服务时意味着要频繁到注册中心请求服务成为性能瓶颈，可以使用缓存来提升性能。第三点是服务端处理大量RPC请求时也可能成为瓶颈，一个是服务端处理业务时使用线程池处理，第二点可以使用负载均衡。</li>
</ul>
<h1 id="问题排查及解决方案"><a href="#问题排查及解决方案" class="headerlink" title="问题排查及解决方案"></a>问题排查及解决方案</h1><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><p><strong>定位</strong></p>
<ul>
<li>开启慢日志</li>
<li>Explain（模拟优化器执行）<ul>
<li>key：使用的索引</li>
<li>type: system（表中只有一行数据) ，const(只有一行索引匹配)，eq_ref（主键或唯一索引的等值连接），ref（非主键非唯一索引），range（索引范围），index（全表索引），all（全表扫描）</li>
</ul>
</li>
</ul>
<p><strong>优化角度</strong></p>
<ul>
<li>数据量<ul>
<li>数据量越大IO次数越多</li>
</ul>
</li>
<li>取数据方式<ul>
<li>磁盘还是缓存</li>
<li>是否能结合谓词条件命中全局索引</li>
</ul>
</li>
<li>数据加工方式<ul>
<li>排序、子查询、聚合、关联等取到临时表中，对数据加工</li>
<li>合适的join方式</li>
</ul>
</li>
</ul>
<p><strong>优化思路</strong></p>
<ul>
<li><p>减少数据扫描</p>
<ul>
<li><p>数据分页优化</p>
<blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">select * from table_demo <span class="type">where</span> <span class="variable">type</span> <span class="operator">=</span> ?  limit A,B; </span><br><span class="line">---limit+offset，每次查询B条数据都要扫描跳过前A-<span class="number">1</span>条数据</span><br><span class="line"></span><br><span class="line">lastId = <span class="number">0</span> or <span class="title function_">min</span><span class="params">(id)</span></span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">select * from table_demo <span class="type">where</span> <span class="variable">type</span> <span class="operator">=</span> ? and id &gt;&#123;#lastId&#125;  limit ?;</span><br><span class="line">lastId = max(id)</span><br><span class="line">&#125; <span class="keyword">while</span> (isNotEmpty)</span><br><span class="line">---记录偏移ID，新页直接定位到上一次的<span class="type">ID</span></span><br><span class="line"></span><br><span class="line"><span class="variable">minId</span> <span class="operator">=</span> min(id) maxId = max(id)</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> minId; i&lt;= maxId; i+=pageSize)&#123;</span><br><span class="line">select * from table_demo <span class="type">where</span> <span class="variable">type</span> <span class="operator">=</span> ? and id between i and i+ pageSize;</span><br><span class="line">&#125;</span><br><span class="line">--- between and，分段查询 虽然可以减少扫描遍历情况，但是不适用于查询的键分布不均的情况，多了一些不必要的查询</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>Groud By分组优化</p>
<blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select job , avg(sal) from table_demo <span class="type">where</span>  <span class="variable">job</span> <span class="operator">=</span> ‘manager<span class="string">&#x27; group by job</span></span><br><span class="line"><span class="string">先过滤后分组</span></span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>范围查询</p>
<blockquote>
<p>单键索引: 查询到主键索引时，先排序后回表Multi Range Read(MRR)），可以减少IO次数（一个页中有多个连续行）</p>
<p>联合索引：Mysql5.6+，等式放范围查询的右边会通过索引下推过滤回表的主键数，当然：等值最左匹配才是优解</p>
</blockquote>
</li>
<li><p>Order By</p>
<blockquote>
<p>索引覆盖排序 ：order前建立索引时已经排好序</p>
</blockquote>
</li>
<li><p>业务划分</p>
<blockquote>
<p>date &#x3D; now; minDate &#x3D; now - 10 days<br>while(date &gt; minDate) {<br>select * from order where order_date&#x3D;{<em>#date} and status&#x3D;’S’ and update_time &lt; now-5min limit 500</em>  date &#x3D; data + 1}</p>
<p>对比: 快在可以对order_date索引（status如果太均匀失效了），避免一次性读太大量的表进内存</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from order where status=<span class="string">&#x27;S&#x27;</span> and update_time &lt; now-5min  limit <span class="number">500</span></span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
</li>
<li><p>数据库结构优化</p>
<ul>
<li>范式优化：消除冗余</li>
<li>反范式优化：适当加冗余-避免join操作（有时候不满足第三范式也能提升速度）</li>
<li>按物理结构拆分表，避免全表扫描（例如按日期）</li>
</ul>
</li>
<li><p>SQL语句优化</p>
<ul>
<li>区分 in 和 exists（in先执行子查询后逐行判断-适合内表小的情况（子查询返回的结果少），后者遍历外表逐行执行子查询，遇到匹配项停止减少扫描。因为每次子查询需要开销，在少量数据的时候还是用in）</li>
<li>尽量避免使用子查询-&gt;join&#x2F;反范式优化</li>
</ul>
</li>
<li><p>大表优化</p>
<ul>
<li>分库分表</li>
<li>读写分离（主从复制）</li>
<li>定期归档（历史数据移除，减少主表大小）</li>
</ul>
</li>
</ul>
<h2 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h2><h2 id="接口超时"><a href="#接口超时" class="headerlink" title="接口超时"></a>接口超时</h2><h2 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h2><h1 id="海量数据处理"><a href="#海量数据处理" class="headerlink" title="海量数据处理"></a>海量数据处理</h1><h2 id="高频统计类"><a href="#高频统计类" class="headerlink" title="高频统计类"></a>高频统计类</h2><h3 id="TOP-K问题-次数出现最多元素"><a href="#TOP-K问题-次数出现最多元素" class="headerlink" title="TOP K问题 &#x2F; 次数出现最多元素"></a>TOP K问题 &#x2F; 次数出现最多元素</h3><ul>
<li>方法一：首先将大文件转成小文件：具体来说，可用使用Hash元素取模M分成M个小文件，目的是将相同的元素放在同一文件中。然后，将小文件加载进内存中用HashMap记录元素出现次数，遍历HashMap构造有100个节点的小根堆。接下来就是遍历所有文件，重复HashMap记录次数，然后将元素次数和小根堆堆顶元素比较，若大于其则交换重构堆。—-该方法不足之处在于，若大量元素都相似，容易导致生成的小文件过大，大于内存。</li>
<li>方法二：首先先对文件里的字符串排序，保证相同的字符串连续。具体来说：大文件顺序按固定大小切分为子文件，子文件分别进内存后对字符串排序。使用多路归并排序，即初始化M个结点的最小堆，每个结点代表各子文件输入流的第一个元素，从最小堆中取出最小元素，并将其写入输出文件，同时堆顶元素对应文件读入下一个元素放入堆中，重复过程直至大文件有序。 然后，维护一个K结点的最小堆，节点为元素对应出现次数，遇到新元素则统计完元素数量后元堆顶元素比较，若大于则取出堆顶元素并加入。</li>
</ul>
<h2 id="存在性判断与去重"><a href="#存在性判断与去重" class="headerlink" title="存在性判断与去重"></a>存在性判断与去重</h2><h3 id="判断元素存在"><a href="#判断元素存在" class="headerlink" title="判断元素存在"></a>判断元素存在</h3><ul>
<li>方法一：排序后，遍历</li>
<li>方法二：位图法：40亿个整数可以用2的32次方表示，也就是512MB。初始化个数组位为0，若数字存在对应位置置1，遍历位图。</li>
</ul>
<h3 id="找出不重复元素"><a href="#找出不重复元素" class="headerlink" title="找出不重复元素"></a>找出不重复元素</h3><ul>
<li>方法一：排序后，遍历</li>
<li>方法二：位图法：40亿个整数可以用2的32次方表示，2bit作为信息为 00为不存在 01为1个元素 10为重复元素，2*512MB&#x3D;1GB</li>
</ul>
<h2 id="交集与合并的问题"><a href="#交集与合并的问题" class="headerlink" title="交集与合并的问题"></a>交集与合并的问题</h2><h3 id="大文件交集"><a href="#大文件交集" class="headerlink" title="大文件交集"></a>大文件交集</h3><ul>
<li>两个大文件用相同的哈希函数和取模基数，保证相同的URL都在相同序号的子文件中。只要比较子文件的内容即可</li>
</ul>
<h2 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h2><ul>
<li>从最高位开始划分数据，进而到次高进制，重复过程直到定位到中位数所在区间并且满足内存空间大小</li>
</ul>

    </div>

    
        <hr class="fhr">
        <div id="vcomments"></div>
    
</div>
    <div class="footer" id="footer">
    <p><h4>Copyright © 2020 | Author: 食芒果冰 | Theme By <a class="theme-author" target="_blank" rel="noopener" href="https://github.com/Xunzhuo/hexo-theme-coder" style="font-size:14px; color: #969696">Coder</a></h4>
    
    <label class="el-switch el-switch-blue el-switch-sm" style="vertical-align: sub;">
        <input type="checkbox" name="switch" id="update_style">
        <span class="el-switch-style"></span>
    </label>

    <!--         <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1278548644'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D1278548644%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
    </script> -->
</p>
</div>

<input type="hidden" id="web_style" value="black">
<input type="hidden" id="valine_appid" value="">
<input type="hidden" id="valine_appKey" value="">

<script src="/libs/jquery.min.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>

<script src='//cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>

<script src="/js/js.js"></script>

<style type="text/css">
.v * {
color: #698fca;
}
.v .vlist .vcard .vhead .vsys {
color: #3a3e4a;
}
.v .vlist .vcard .vh .vmeta .vat {
color: #638fd5;
}
.v .vlist .vcard .vhead .vnick {
color: #6ba1ff;
}
.v a {
color: #8696b1;
}
.v .vlist .vcard .vhead .vnick:hover {
color: #669bfc;
}
</style>
    <script type="text/javascript" color="173,174,173" opacity='1' zIndex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
</body>
</html>
