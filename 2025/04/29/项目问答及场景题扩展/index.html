<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="google-site-verification" content="TZE0rZyIqLl10trYu3BWBWa1Vmz6HFwhb2OcNEK4u-s" />
     <link rel="shortcut icon" href= /img/favicon.ico >
    <title>
        部落格
    </title>
    <meta name="description" content= 千里之行，始于足下 >
    <meta name="keywords" content= Blog >
    
<link rel="stylesheet" href="/libs/highlight/styles/monokai-sublime.css">

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="部落格" type="application/atom+xml">
</head>
<body id="bodyx">
    <div class="hd posts">
    <a href="/index.html"><i class="fa fa-home
 replay-btn" aria-hidden="true"></i></a>
    <div class="post-title">
        <p>
            项目问答及场景题扩展
        </p>
        <hr>
    </div>
    <div class="post-content">
        <h1 id="生意卡"><a href="#生意卡" class="headerlink" title="生意卡"></a>生意卡</h1><h2 id="介绍一下项目？里面有什么亮点难点？"><a href="#介绍一下项目？里面有什么亮点难点？" class="headerlink" title="介绍一下项目？里面有什么亮点难点？"></a>介绍一下项目？里面有什么亮点难点？</h2><p>生意卡是一个TOB端的业务，主要用于降低商户的采购成本。我觉得比较有挑战性的一点，就是第二周开始，就接到了一个比较大的需求，就是支持商户自助下载交易流水。</p>
<h2 id="商户自助交易流水导出设计"><a href="#商户自助交易流水导出设计" class="headerlink" title="商户自助交易流水导出设计"></a>商户自助交易流水导出设计</h2><p>首先是产品同事提出这个需求，可以使商家可以自助下载自己的交易流水。目标有几个点，第一，要提升用户体验，不能让其长时间等。第二，要保护下游的服务，限制用户单日导出的频次，防止资源被拖垮。第三个，同一个商户不能重复导出一个时间段的流水，防止重复点击浪费导出次数。我的设计方案分四步，首先是通过MQ异步去解耦文件生成的过程，用户在点击导出后会立即返回正在导出的状态。为了限制导出次数，基于redis实现分布锁并且将其作为计数器，商户id+导出日期作为key，过期时间设计为24小时。每次导出前上锁，检查计数。第三步就是将文件上传到OSS并返回带过期时间的链接。最后就是链接落库，用户刷新后可以看到下载链接。接口现在TP99稳定在150ms以内。</p>
<p><strong>1. 为什么选择MQ？直接用线程池异步处理不行吗？</strong>同步不行吗</p>
<ul>
<li>线程池异步处理在简单的场景下可以，但有局限性。一个是考虑可靠性，线程池基于内存的，应用重启就丢失了。MQ本身有持久化能力可以保证最终一致性。 第二点，MQ削峰填谷的能力，如果以后访问量大的话也能。</li>
<li>若用同步，下游IO较多，用户HTTP请求被阻塞，用户体验不好。</li>
</ul>
<p><strong>2. 你的Redis分布式锁是怎么实现的？如何保证原子性？如何避免死锁？</strong></p>
<ul>
<li><p>首先无论是上锁还是删锁其实都已经封装到了很成熟的API。其实底层redis代码，上锁就是用 set key value NX EX 加过期时间。这条命令是原子的，NX就是键不存在时才设置，EX过期时间保证有锁客户端崩溃形成死锁。</p>
<ul>
<li><p>锁误删的问题：A过期时间导致释放锁，B加锁，A执行完任务把B锁删了。原因是del时只看key，应该get-del通过Lua脚本保证原子。</p>
</li>
<li><p>高可用：单台奔溃了，其他客户端可以进入临界区如何解决。RedLock，超半数知道你获得锁或者删除锁了。</p>
</li>
</ul>
</li>
</ul>
<p><strong>3. 你们ES的数据同步方案是什么？如何保证数据一致性？</strong> </p>
<ul>
<li>我们这边的用的方案是将Mysql的数据MQ异步到ES，延时在秒级别。业务上允许短暂的延迟，属于<strong>最终一致性</strong>。如果业务要求强一致，一个考虑牺牲性能做同步。或者加缓存，缓存最近的数据，查询时先查缓存。</li>
</ul>
<p><strong>4. 如果导出过程中失败了怎么办？</strong></p>
<ul>
<li>MQ层面消费重试</li>
<li>应用层兜底，超重试次数告警</li>
</ul>
<p><strong>5. 为什么用OSS？直接返回文件流不行吗？</strong></p>
<ul>
<li>方便扩容，保存本地磁盘扩容要复制多份</li>
<li><strong>性能</strong>：OSS专为文件读写优化，下载速度远快于从应用服务器拉取</li>
</ul>
<h2 id="会员列表余额查询性能调优"><a href="#会员列表余额查询性能调优" class="headerlink" title="会员列表余额查询性能调优"></a>会员列表余额查询性能调优</h2><ol>
<li><strong>“线程池的核心参数你是怎么设置的？为什么要这么设置？”</strong></li>
</ol>
<ul>
<li>首先是核心参数，机器是4c8g的，这是一个IO频繁的接口，所以按经验公式用的是2倍的核心数，也就是8，我这里多设了点为10。至于最大核心数的话，首先该接口测试平均时延响应在80ms左右，设置其超时时间为200ms，也就是说一个线程1s至少能执行5次任务。为了保证接口稳定，导师建议QPS在100左右，所以最大线程数就是拿100&#x2F;5&#x3D;20个最大线程。至于阻塞队列，考虑到会员列表数量通常不会超过100个，为了保证内存不OOM，设置有界队列长度为100。拒绝策略用的是callRunPolicy，也就是用用户请求线程执行，避免任务丢失，同时也会让调用端快速感知到后端压力。</li>
</ul>
<ol start="2">
<li>“如果某个RPC调用失败了或者超时了，你是怎么处理的？”</li>
</ol>
<ul>
<li>如果失败或超时，打日志并返回一个null值，前端做过滤。保证了<strong>部分失败不影响整体</strong>。另外也可以统计失败率作为告警。</li>
</ul>
<ol start="3">
<li>“你是怎么控制并发度，防止把下游服务打垮的？”</li>
</ol>
<ul>
<li>最大线程池和RPC的超时时间</li>
</ul>
<h2 id="会员额度迁移接口设计"><a href="#会员额度迁移接口设计" class="headerlink" title="会员额度迁移接口设计"></a>会员额度迁移接口设计</h2><p>这个是最近生意卡业务升级了功能，每个商户将余额划分为充值余额和结算余额，所以需要将迁移消息和账务系统的同事同步。这个方案主要是要保证数据准确。具体来说，设计定时任务在凌晨时批量执行任务，迁移的过程需要多次IO，所以用MQ去异步执行。为了防止消息重复消费，使用唯一生意卡号上锁，其实就分成4个步骤，冻结账户，创建新账户，初始化余额，解冻账户。调用接口可能会有超时的情况会自动重试，为了保证每个子步骤的幂等性，通过生成唯一的请求号，在请求前都会生成每个子步骤失败都会告警。</p>
<p>1.<strong>如何生成唯一请求号？</strong></p>
<ul>
<li><p>类似雪花算法，应用+机器数量+时间戳+序号，但序号在单机通过加锁保证增加</p>
<ul>
<li><p>雪花算法，符号位+时间戳+机器表示+序列号（原子自增）</p>
</li>
<li><p>时间回拨问题 ：和服务器同步时间，时钟往回调。此时如果不做处理，就会说生成重复的自增ID，解决方案，短时间内可以阻塞等待now等于上一次的timeStamp。长时间的话抛异常，或者加拓展位，回拨对应位+1，像版本号</p>
</li>
</ul>
</li>
</ul>
<p><strong>2.如果迁移过程中某个商户账户正在发生交易，怎么办？</strong></p>
<ul>
<li>在迁移前会查询是否有交易在途，如果没有则向账务系统发起账户冻结请求。</li>
</ul>
<p><strong>3. 你们是怎么保证MySQL和MQ之间的数据一致性的？</strong>	</p>
<ul>
<li>用的是本地事务表的方案。具体来说，就是将在发送MQ前，先将MQ消息落库。将该操作和业务落库的操作放在同一事务里。当MQ消息落库成功，但发送失败，定时任务扫库重发。</li>
</ul>
<h2 id="存量商户账户批量初始化"><a href="#存量商户账户批量初始化" class="headerlink" title="存量商户账户批量初始化"></a>存量商户账户批量初始化</h2><ol>
<li><p>“为什么设计成‘定时任务+MQ’的架构？直接用一个脚本批量插入数据库不行吗？”</p>
<p>一个是可以方便地控制每次拉取的数量（Batch Size），并通过MQ的管控台清晰看到消息堆积情况，便于监控和告警。另外MQ具有持久化机制。即使消费者服务暂时宕机，消息也不会丢失.</p>
</li>
</ol>
<ul>
<li>逻辑解耦，方便调试。任务触发模块和执行模块拆分，两者可以独立测试。</li>
<li><strong>削峰填谷与流量控制</strong></li>
</ul>
<ol start="2">
<li><p>“为什么既用了Redis分布式锁，又要做幂等性校验？是不是重复了？”</p>
</li>
<li><p>“什么是幂等性，幂等性具体是怎么实现的？为什么不用数据库的乐观锁？”</p>
</li>
<li><p>“唯一请求号（request_id）是怎么生成的？</p>
</li>
<li><p>“如果某个商户账户创建失败，一直重试都失败，怎么办？”</p>
</li>
<li><p>“如果在‘插入幂等表’后，执行业务逻辑之前消费者宕机了，会不会导致数据不一致？”</p>
</li>
</ol>
<h2 id="交易流水查询接口优化"><a href="#交易流水查询接口优化" class="headerlink" title="交易流水查询接口优化"></a>交易流水查询接口优化</h2><ul>
<li>这个问题是我向导师提的一个技改需求，当时做第一个需求好奇为什么限制ES查询10000条数据，查原因是为了保证检索性能设置了一个深分页的最大值。所以目标就是解决这个瓶颈，让用户可以查询更深的历史数据。传统的<code>from + size</code>方式在深度分页时性能骤降的根本原因是：它需要在每个分片上先查出<code>from + size</code>条数据，然后协调节点将这些结果汇总，再排序并截取<code>from</code>到<code>from+size</code>的部分返回。时间复杂度是O（n）各分片找from + size条归并。<strong>Search After</strong>: 它的原理是使用上一页的排序值作为‘游标’来定位下一页的起始点，即在各分片定位到&gt;&#x3D;该id的数据，找size条归并。<strong>性能是常数<code>O(1)</code>的</strong>。<code>Search After</code>要求排序字段的值必须唯一，采用的排序ID为业务ID（？）。<strong>scroll</strong>是维护一个快照，记录_scroll_id-（<strong>文件号+行号</strong>），每次根据上一次段号往下找size各个数据，牺牲实时性，适合离线数据。</li>
</ul>
<p><strong>1. 前端如何适配？如果用户直接输入一个很大的页码，比如第1000页，怎么办？</strong></p>
<ul>
<li>我设计的是如果不传字段则走page_size逻辑支持跳页，若传入则只能前后翻页，和产品同步</li>
</ul>
<p><strong>2. 如果排序字段的值不唯一会有什么后果？</strong></p>
<p>这些记录的排序顺序在不同分页请求中可能不一致，导致某些记录被重复看到，而另一些被跳过</p>
<h2 id="商户中心产品列表查询优化"><a href="#商户中心产品列表查询优化" class="headerlink" title="商户中心产品列表查询优化"></a>商户中心产品列表查询优化</h2><ul>
<li>需求背景是，有个查询产品列表接口通过告警发现偶尔会超时，该接口是写在一个大的查询接口里，直接导致我们整个页面加载失败，用户只能看到错误提示。一个是防止页面奔溃体验感不好，一个是数据时效性不能太久。首先第一点先把接口拆分出来，不让其影响整个接口。第二点是分析了业务逻辑，发现产品的开通状态是一个<strong>变化频率很低</strong>的数据（一个商户一天内通常不会频繁开通、取消产品），所以引入缓存机制。</li>
</ul>
<p><strong>1. 缓存时间（TTL）为什么设置成1天？考虑过数据一致性吗？</strong></p>
<ul>
<li>和产品确认过，产品开通状态是一个低频变更的数据，延迟1天对业务的影响是可接受的。</li>
</ul>
<p><strong>2. 如果缓存穿透了（比如查一个不存在的商户ID），大量请求打到下游怎么办？</strong></p>
<ul>
<li>缓存控制null&#x2F;布隆过滤器</li>
</ul>
<p><strong>3. 有没有考虑过缓存雪崩？如果大量缓存同时失效怎么办？</strong></p>
<p>第一，在设置缓存过期时间时，增加了一个<strong>随机扰动值</strong>（比如1小时 ± 5分钟），避免大量缓存在同一时刻失效。第二，在应用层面，我使用了<strong>互斥锁（Mutex Lock）</strong> 机制：当缓存失效时，只允许一个线程去回源加载数据，其他线程等待，而不是全部同时涌向下游服务</p>
<h2 id="OSS云存储安全治理"><a href="#OSS云存储安全治理" class="headerlink" title="OSS云存储安全治理"></a>OSS云存储安全治理</h2><ul>
<li>风控检查</li>
</ul>
<p><strong>1. 签名URL的过期时间你是怎么设定的？</strong></p>
<p>这是一个业务权衡。对于对账单下载场景，用户在页面操作后，通常会在几分钟内完成下载。我们设置为<strong>30分钟</strong>，这个时间窗口既能保证用户体验（不会因为URL很快失效而操作中断），又不会让签名链接过长时间暴露</p>
<h2 id="ES"><a href="#ES" class="headerlink" title="ES"></a>ES</h2><h4 id="1-倒排索引（Inverted-Index）是什么？为什么它比正排索引快？"><a href="#1-倒排索引（Inverted-Index）是什么？为什么它比正排索引快？" class="headerlink" title="1. 倒排索引（Inverted Index）是什么？为什么它比正排索引快？"></a>1. 倒排索引（Inverted Index）是什么？为什么它比正排索引快？</h4><ul>
<li>倒排索引是一种类似于“词语-&gt;文档”映射的索引结构。它由两部分组成，<strong>Term Dictionary（词项字典）</strong>：记录所有出现的单词，并排序。<strong>Posting List（倒排列表）</strong>：记录每个单词在哪些文档中出现，以及出现的位置、频率等信息。</li>
</ul>
<h4 id="2-ES-的-Index、Type、Document-是什么？现在还有-Type-的概念吗？"><a href="#2-ES-的-Index、Type、Document-是什么？现在还有-Type-的概念吗？" class="headerlink" title="2. ES 的 Index、Type、Document 是什么？现在还有 Type 的概念吗？"></a>2. ES 的 Index、Type、Document 是什么？现在还有 Type 的概念吗？</h4><ul>
<li><strong>Index</strong>：类比于数据库中的<strong>Database</strong>，是一类文档的集合。<strong>Type</strong>：类比于数据库中的<strong>Table</strong>，<strong>Document</strong>：类比于数据库中的<strong>Row</strong></li>
</ul>
<h4 id="3-分片（Shard）和副本（Replica）是什么？为什么要这么设计？"><a href="#3-分片（Shard）和副本（Replica）是什么？为什么要这么设计？" class="headerlink" title="3. 分片（Shard）和副本（Replica）是什么？为什么要这么设计？"></a>3. 分片（Shard）和副本（Replica）是什么？为什么要这么设计？</h4><ul>
<li><strong>分片（Shard）</strong>：一个索引可以分成多个部分，每个部分就是一个分片。分片是数据的容器，分布在不同的节点上。<strong>副本（Replica）</strong>：每个分片可以有零个或多个副本。副本是分片的完整拷贝。<strong>副本提供了高可用性和读操作的负载均衡</strong>。</li>
</ul>
<ol start="4">
<li>倒排索引的更新</li>
</ol>
<ul>
<li>（早期）索引写入磁盘后不变（不需要锁，缓存和磁盘强一致性）-&gt;每次需重新构建整个索引</li>
<li>新文档收集到内存索引缓存，缓存提交为新的段追加进磁盘。</li>
</ul>
<ol start="5">
<li>查询过程</li>
</ol>
<ul>
<li>所有已知段按顺序被查询，统计关联程度最高的文档id</li>
</ul>
<ol start="6">
<li>文档删除</li>
</ol>
<ul>
<li>.del文件标识哪些文件被删除。查出结果后，根据.del文件去除结果并返回。</li>
</ul>
<ol start="7">
<li>文档写入</li>
</ol>
<ul>
<li>客户端发送写请求到协调节点，node路由分片并转发，分片更新后同步副本，副本反馈，向协调节点反馈</li>
</ul>
<h1 id="餐饮订购系统"><a href="#餐饮订购系统" class="headerlink" title="餐饮订购系统"></a>餐饮订购系统</h1><h3 id="介绍一下项目？里面有什么亮点难点？-1"><a href="#介绍一下项目？里面有什么亮点难点？-1" class="headerlink" title="介绍一下项目？里面有什么亮点难点？"></a>介绍一下项目？里面有什么亮点难点？</h3><p>我设计的是一个餐饮订购平台，其包括优惠券秒杀，用户登录，订单和库存管理等核心功能。在技术上，商品浏览和购物车模块通常请求量较大所以引入redis缓存加快请求响应，但引入缓存后考虑到可能会有缓存穿透的问题，所以加入布隆过滤器对非法数据进行过滤。用户在下单支付后，需要通知商家发货，所以使用了可以服务器主动推送的Websock协议，用户在下单后可能会未支付，需要对这些订单进行处理，这可以用延时队列来处理，考虑到RocketMQ提供了延时队列的功能，并且能保证消息的可靠传输，所以将消息投递到消息队列中，超时后被消费，修改订单状态。除此之外，在优惠券抢购中，在这种高并发的场景下，有两个难点需要被解决，一个是防止超卖，另外一个因为库存被预热到redis中，还需要考虑redis和DB的一致性。针对超卖的问题，其引发的原因主要是多个用户即多个线程同时读写库存，我使用的解决方案是lua脚本执行原子性读写。针对一致性的问题，也是使用RocketMQ的ACK和重传机制保证最终一致性。	</p>
<h2 id="登录模块"><a href="#登录模块" class="headerlink" title="登录模块"></a>登录模块</h2><h2 id="介绍一下登录流程？服务端是如何记住用户登录状态的？"><a href="#介绍一下登录流程？服务端是如何记住用户登录状态的？" class="headerlink" title="介绍一下登录流程？服务端是如何记住用户登录状态的？"></a>介绍一下登录流程？服务端是如何记住用户登录状态的？</h2><ul>
<li>登录流程基于JWT+拦截器的无状态鉴权体系：用户在提交账号密码后，服务端验证并生成Json web token 返回给客户端，客户端在后续请求中携带该Token，服务器通过拦截器解析Token并验证用户身份。</li>
</ul>
<h2 id="需要我再讲讲具体的签名验证过程吗？"><a href="#需要我再讲讲具体的签名验证过程吗？" class="headerlink" title="需要我再讲讲具体的签名验证过程吗？"></a>需要我再讲讲具体的签名验证过程吗？</h2><ul>
<li>JWT由三部分组成，分别是Header，payload，signature。首次生成signature时，对Header和payload和服务器密钥用算法加密生成签名。后续获取到token只要比对签名就可以判断内容是否被篡改。</li>
</ul>
<h3 id="为什么选择JWT而不是Session-Cookie机制？"><a href="#为什么选择JWT而不是Session-Cookie机制？" class="headerlink" title="为什么选择JWT而不是Session-Cookie机制？"></a>为什么选择JWT而不是Session-Cookie机制？</h3><p>首先第一个点JWT是无状态的，也就是说在服务器端不需要存储其他额外的信息，一个是减轻了服务器的负担，另一个就是Session-Cookie机制这种机制的话，对于在分布式场景下，需要多个服务器去同步同一个用户的信息，增加开销。第二个点就是JWT更加安全，对于跨域请求伪造，cookies在每次请求的时候都会自动发送，以至于被攻击，而jwt可以放在请求头的authorization里面，在需要时才发送</p>
<ul>
<li>jwt之所以不受同源限制是因为他需要显示添加到请求头，用户自定义控制风险。Cookies是发送请求时自带，为了避免CSRF需要同源限制</li>
</ul>
<h2 id="如果密钥泄露导致Token被伪造，如何快速发现和止损？"><a href="#如果密钥泄露导致Token被伪造，如何快速发现和止损？" class="headerlink" title="如果密钥泄露导致Token被伪造，如何快速发现和止损？"></a>如果密钥泄露导致Token被伪造，如何快速发现和止损？</h2><ul>
<li>可以采用双token方案，access token 用于鉴权并设立较短的时间， fresh token 设立较长的过期时间，服务端需记录其绑定的用户ID和设备信息，以便检测异常使用。当检测access token到期时，根据fresh token 重新生成新的access token。</li>
</ul>
<h3 id="拦截器和过滤器的底层原理"><a href="#拦截器和过滤器的底层原理" class="headerlink" title="拦截器和过滤器的底层原理"></a>拦截器和过滤器的底层原理</h3><ul>
<li>前端发送请求先到DispatcherServlet，然后到HandlerMapping匹配Hander，再到Hander Adaptor执行Handle，拦截器处理器执行前执行prehandle，视图渲染前执行postHandle,浏览器响应前执行afterComplete。拦截Spring管理的Controller请求，适用认证与权限验证。执行顺序Filter前置-&gt;Interceptor-&gt;Filter后置</li>
<li>过滤器底层是执行回调函数，处理粒度是在HTTP请求和响应层面，适用全局编码处理。拦截器体现AOP思想，即对web请求应用同一组方法，分别在处理器执行前执行prehandle，视图渲染前执行postHandle,浏览器响应前执行afterComplete。拦截Spring管理的Controller请求，适用认证与权限验证。执行顺序Filter前置-&gt;Interceptor-&gt;Filter后置</li>
<li>（Spring MVC）拦截器执行顺序 查找处理器-&gt;prehandle-&gt;处理器执行-&gt;postHandle-&gt;视图渲染-&gt;afterComplete-&gt;浏览器响应</li>
</ul>
<h3 id="为什么使用ThreadLocal？"><a href="#为什么使用ThreadLocal？" class="headerlink" title="为什么使用ThreadLocal？"></a>为什么使用ThreadLocal？</h3><ul>
<li>一个是为保证了并发安全，在有多个用户登录时，意味着有多个线程访问，使用一个变量例如用户id会出现竞态条件，利用ThreadLocal的线程隔离性，为每个线程分配独立的变量副本，保证线程安全。第二点因为用户登录和订单服务放在同一个服务实例中，如果显示传参太复杂，通过ThreadLocal可以隐式传参，简化代码逻辑。</li>
</ul>
<h3 id="如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？"><a href="#如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？" class="headerlink" title="如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？"></a>如果ThreadLocal里的Entry不用弱引用，需要做哪些处理？在使用类似ThreadLocal这种全局变量还需要注意什么？</h3><ul>
<li>手动处理&#x2F;定时处理&#x2F;任务处理完后遍历处理&#x2F;需要注意一是，如果存储在 <code>ThreadLocal</code> 中的对象是可变的（例如一个可变集合），仍然可能存在线程安全问题&#x2F;如果任务之间不能共享 <code>ThreadLocal</code> 数据，可以考虑为每个任务分配独立的线程&#x2F;需要任务之间共享 <code>ThreadLocal</code> 数据，可以使用 <code>InheritableThreadLocal</code></li>
</ul>
<h2 id="商品浏览模块-购物车模块"><a href="#商品浏览模块-购物车模块" class="headerlink" title="商品浏览模块&#x2F;购物车模块"></a>商品浏览模块&#x2F;购物车模块</h2><h3 id="对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？"><a href="#对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？" class="headerlink" title="对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？"></a>对于项目中布隆过滤器的设计是怎么样的，你为什么这么设计？</h3><ul>
<li>在项目中，为了防止恶意请求访问不存在的商品ID，在redis缓存层之前加了一层布隆过滤器，用于快速判断商品ID是否存在。我是设定项目目前有1w个商品，商品id是64位长整型，误判率设置为0.1%（设置为0.1主要权衡性能和准确性，如果误判率设置太小，意味这着需要更大的位数组，对于电商项目来说，更注重性能），通过公式计算，需要大概18KB的位数组和10个哈希函数。</li>
<li>1000w商品id，误判率0.1%，位数组为17MB，10个哈希函数</li>
</ul>
<h3 id="如果商品数据每日新增百万级，如何动态更新布隆过滤器？"><a href="#如果商品数据每日新增百万级，如何动态更新布隆过滤器？" class="headerlink" title="如果商品数据每日新增百万级，如何动态更新布隆过滤器？"></a>如果商品数据每日新增百万级，如何动态更新布隆过滤器？</h3><ul>
<li>首先我会考虑更新的时机，1个是考虑到白天会有大量用户访问业务，如果这时候更新布隆过滤器会导致短时间的过滤服务停止，会产生缓存穿透问题，所以可以根据访问记录，选择访问数量少的时段，例如定期在凌晨更新，第二个点考虑到更新布隆器时会有过滤服务停止时机，考虑增加一个备份的布隆过滤器，在需要更换的时候直接替换，这时候就是用空间来换时间。第三个点的话可以考虑将布隆过滤器分片，这样每次更新的话，这更新一部分数据的过滤器。第四点的话，也是牺牲性能，考虑使用计数型布隆过滤器。</li>
</ul>
<h3 id="在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？"><a href="#在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？" class="headerlink" title="在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？"></a>在使用Redis缓存热点商品数据和购物车记录中，redis是如何设计的？为什么这么设计？为什么使用redis？</h3><ul>
<li>对于一些商品的基本信息，例如商品名，商品口味等不需要频繁变动的，使用了String类型执行存储，key为商品id，value为JSON字符串。对于购物车这种需要频繁访问和变动的则用Hash来存储，方便随时获取某一字段的value。对比Memcache，提供丰富的数据结构，事务、持久化机制等</li>
</ul>
<h3 id="你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？"><a href="#你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？" class="headerlink" title="你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？"></a>你如何定义“热点商品”？如何自动识别并缓存它们？如果某个热点商品的缓存突然失效，导致大量请求穿透到数据库，如何预防？</h3><ul>
<li>热点商品可以通过商品的访问次数，或者加入到购物车的次数来识别。具体来说，如果是单体项目，可以直接用本地内存例如直接用HashMap去存储商品次数，在分布式环境下，可以使用redis存储。</li>
<li>一个是定期去判断该商品是否为热点商品，如果是就更新过期时间，第二点就是并发控制，在突然失效的时候，控制只让一个线程访问数据，更新缓存。 第三点就是，服务降级嘛，拒绝一些请求，防止系统奔溃。</li>
</ul>
<h3 id="如何保证redis和数据库的一致性？"><a href="#如何保证redis和数据库的一致性？" class="headerlink" title="如何保证redis和数据库的一致性？"></a>如何保证redis和数据库的一致性？</h3><ul>
<li>对于普通商品详情页，是一种读多写少的场景，对于数据一致性要求不是很严格。所以我使用的是旁路缓存，写入数据库后删缓存，虽然它不能保证强一致性，但是它通过过期时间实现最终一致性。对比更新缓存复杂性增加，做更新失败的判断逻辑，另外每次都要将数据放到redis更新。对于延迟双删：需要额外的定时任务或消息队列。当然对于读写穿透，也就是让缓存层同步数据库以保证强一致性，但这种方法给缓存层带来更大的压力的同时，同步意味着需要牺牲性能，所以没采用这种方法。对于热点数据，例如优惠券的库存，我的目标是只要保证最终一致性就行，所以采用异步更新数据库的方式，以提升系统性能。如果要保证强一致的话就要牺牲性能，通过同步的方式保证一致性。</li>
</ul>
<h3 id="如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？"><a href="#如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？" class="headerlink" title="如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？"></a>如果redis缓存删除失败了，或者异步更新数据库失败了怎么办？</h3><ul>
<li>首先缓存删除失败通常可能是网络IO或者redis服务器繁忙的问题，那么可以使用重试机制，根据网络条件设置重试间隔或者避免频繁重试的话可以使用指数退避。当然对于商品详情页来说只要实现最终一致的话，依赖redis的过期时间即可保证最终一致性。在异步更新数据库的时候失败，也可以使用重试的机制，当到达最大重试次数，会投入死信队列，设立定时任务重新将消息重新投递。</li>
</ul>
<h3 id="对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？"><a href="#对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？" class="headerlink" title="对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？"></a>对于redis缓存，购物车模块中为每个用户分配多大内存？500M能存放多少购物车数据？</h3><ul>
<li>首先购物车模块用的是Hash数据结构，一个用户一个商品id为64位整数，8个字节。商品数量设计为4个字节，属性+价格大概20个字节，redis自身Hash额外开销大概在70字节，平均下来一个商品需要100字节。如果每个用户为最大为100个商品，那么就分配10kB的内存。</li>
</ul>
<h3 id="购物车数据用Redis-Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？"><a href="#购物车数据用Redis-Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？" class="headerlink" title="购物车数据用Redis Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？"></a>购物车数据用Redis Hash存储，用户ID为Key，商品ID为Field。如果用户购物车中有数万商品，这个设计会有什么问题？如何优化？如果用户清空购物车，如何保证缓存与DB原子性？</h3><ul>
<li>一个Hash存大量的field意味着，Hash在扩容的时候会按照2的幂次方扩容，那么很容易产生内存碎片。可以考虑对商品按id&#x2F;热点id进行分片。清空购物车保证与DB原子性，清空购物车通常不需要强一致性，可以使用消息队列解耦，用通过重试机制保证最终一致性。如果需要强一致性的话可以使用2PC分布式事务，保证数据库和缓存强一致性。</li>
</ul>
<h3 id="多端（Web-APP）同时修改购物车，如何保证数据正确性？"><a href="#多端（Web-APP）同时修改购物车，如何保证数据正确性？" class="headerlink" title="多端（Web&#x2F;APP）同时修改购物车，如何保证数据正确性？"></a>多端（Web&#x2F;APP）同时修改购物车，如何保证数据正确性？</h3><ul>
<li>在这种并发不高的情况，可以使用redis的watch命令实现乐观锁，watch+key ，如果key对应的value在被更改前被其他线程更改了，则抛出异常执行重试逻辑。当然如果是高并发的场景，可以考虑使用分布式锁，对用户id进行加锁。</li>
</ul>
<h3 id="购物车数据需要持久化吗？何时同步到DB？"><a href="#购物车数据需要持久化吗？何时同步到DB？" class="headerlink" title="购物车数据需要持久化吗？何时同步到DB？"></a>购物车数据需要持久化吗？何时同步到DB？</h3><ul>
<li>对于订餐场景，我考虑的只是作为一直临时性的存储，只存放在redis里面，会话结束后删除。如果希望会话结束之后还存在的话，可以根据实时性需求和性能的取舍，通过实时同步或者批量同步或者异步到数据库</li>
</ul>
<h3 id="你提到在商品浏览和购物车模块中使用了-Redis-缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？"><a href="#你提到在商品浏览和购物车模块中使用了-Redis-缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？" class="headerlink" title="你提到在商品浏览和购物车模块中使用了 Redis 缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？"></a>你提到在商品浏览和购物车模块中使用了 Redis 缓存。那么你是如何设置缓存的过期时间的？有没有考虑过不同的数据类型需要不同的过期策略？</h3><ul>
<li>首先在电商的场景下，基本商品信息通常读多写少，所以我为他们设立了1小时的过期时间。对于商品详情（当然如果商品量比较大redis内存有限，可以根据商品的访问频率来设定过期时间，热门商品可以设立更长的过期时间），对于购物车来说，写操作比较频繁，过期时间可以更短。那么处理过期的商品信息有几种方案，一个是为每个key开启定时器，则直接删除对应的key，或者使用延时队列处理，这两张方法精确度比较高，但是随着key的增多，定时器的开销和队列的开销会上升。通过redis懒删除+定期随机抽样删除的方式处理过期商品，通过设立定期抽样删除的频率做性能和内存回收的权衡嘛，懒删除的话可以保证过期商品可以被正确处理</li>
</ul>
<h3 id="你的-Redis-实例是如何配置淘汰策略的？是使用默认的-LRU-策略，还是选择了其他策略？为什么？"><a href="#你的-Redis-实例是如何配置淘汰策略的？是使用默认的-LRU-策略，还是选择了其他策略？为什么？" class="headerlink" title="你的 Redis 实例是如何配置淘汰策略的？是使用默认的 LRU 策略，还是选择了其他策略？为什么？"></a>你的 Redis 实例是如何配置淘汰策略的？是使用默认的 LRU 策略，还是选择了其他策略？为什么？</h3><ul>
<li>对于这个系统来说，对于商品浏览和购物车来说是，是典型的热点数据频繁访问，LRU也就是最近最少使用访问淘汰策略，可以更好识别出热门商品数据，其他淘汰策略例如随机淘汰，适合访问频率比较均匀的。LFU虽然长期来看也能鉴别出热门数据，但是它的实现是要为每个key维护一个计数器以统计频率，可能会有开销。</li>
</ul>
<h3 id="热点-Key-问题解决方案"><a href="#热点-Key-问题解决方案" class="headerlink" title="热点 Key 问题解决方案"></a>热点 Key 问题解决方案</h3><ul>
<li>本地缓存，热点分片（分片算法），提前预热</li>
</ul>
<h3 id="Redis-大key会有什么问题？解决方案？"><a href="#Redis-大key会有什么问题？解决方案？" class="headerlink" title="Redis 大key会有什么问题？解决方案？"></a>Redis 大key会有什么问题？解决方案？</h3><ul>
<li>删除时单线程阻塞，持久化开销大：RDB AOF，网络IO,主从复制&#x2F;业务分片，按字段切分</li>
</ul>
<h3 id="订单模块"><a href="#订单模块" class="headerlink" title="订单模块"></a>订单模块</h3><h3 id="为什么使用Websock？"><a href="#为什么使用Websock？" class="headerlink" title="为什么使用Websock？"></a>为什么使用Websock？</h3><ul>
<li>首先相比于传统的HTTP请求（即使是短轮询或者长轮询），WebSocket提供更低的延迟，因为它本身就是建立了持久连接。其次它允许服务端主动向客户端推送消息。所以比较适合订餐系统中及时通知商家的场景。</li>
</ul>
<h3 id="WebSocket建立过程"><a href="#WebSocket建立过程" class="headerlink" title="WebSocket建立过程"></a>WebSocket建立过程</h3><ul>
<li>首先客户端向服务端发送一个Http请求，里面包含websocket的路径，upgrade字段设置为websocket。</li>
</ul>
<h3 id="如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？"><a href="#如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？" class="headerlink" title="如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？"></a>如何保证商户在线时实时接收订单通知？若商户离线一段时间后重新上线，如何补发未处理的订单通知？</h3><ul>
<li>首先websock建立的是持久连接，并且使用了心跳机制，通过定期给客户端发送ping检测网络断连，断联后可以考虑使用指数退避算法避免频繁重连。如果商户离线，未处理的订单通知可以先放进消息队列，等到重连后客户端再重新消费。或者将未处理订单记录放进表中，商户上线后服务端查询订单未读通知，重新推送，再或者存入Redis Sorted Set（按时间排序），按时间取出消息重新推送。可以通过使用Nginx将根据商户id，将websock连接分配到不同服务实例。</li>
</ul>
<h3 id="WebSocket-性能有什么问题？WebSocket-服务如何横向扩展以支持10万级商户同时在线？"><a href="#WebSocket-性能有什么问题？WebSocket-服务如何横向扩展以支持10万级商户同时在线？" class="headerlink" title="WebSocket 性能有什么问题？WebSocket 服务如何横向扩展以支持10万级商户同时在线？"></a>WebSocket 性能有什么问题？WebSocket 服务如何横向扩展以支持10万级商户同时在线？</h3><ul>
<li>连接开销大，每个websocket连接都要占用服务器资源，并发量大的时候会造成压力。另外为了保持连接活跃并检测断线情况，通常需要定期发送心跳包，增加服务器负担。可以水平拓展多个websocket实例，使用反向代理服务器来分发 WebSocket 连接到多个后端服务器实例上，确保每个服务器处理的连接数在一个可接受的范围内。</li>
</ul>
<h3 id="如何防止网络抖动导致消息丢失？"><a href="#如何防止网络抖动导致消息丢失？" class="headerlink" title="如何防止网络抖动导致消息丢失？"></a>如何防止网络抖动导致消息丢失？</h3><ul>
<li>为每个消息生成唯一的ID，加入确认机制，如果没收到ack就重传。对于重要消息可以通过消息队列来传输，因为RocketMQ或kafka会提供可靠性保障。</li>
</ul>
<h3 id="为什么使用RocketMQ处理超时订单？"><a href="#为什么使用RocketMQ处理超时订单？" class="headerlink" title="为什么使用RocketMQ处理超时订单？"></a>为什么使用RocketMQ处理超时订单？</h3><ul>
<li>首先它支持延迟消息，生产者发送带延迟消息的订单，消息在指定时间之后才允许被消费。第二个就是对比直接使用数据库定时任务，去查询超时订单，可以减轻数据库压力，也就是说在高并发场景下效果更好。最后就是，它提供可靠的消息传递，通过重试机制，和死信队列保证最终一致性。当然使用Redis的Zset也可以实现延时队列的功能，但是每次需要轮询Zset触发处理到期任务，在数据量较大的适合性能产生瓶颈</li>
</ul>
<h3 id="超时订单技术选型"><a href="#超时订单技术选型" class="headerlink" title="超时订单技术选型"></a>超时订单技术选型</h3><ul>
<li>JAVA自带的DelayQueue优先队列，轮询队列头部，牺牲内存，不适合分布式处理。RocketMQ每个订单对应一条消息，且不会马上消费，给MQ带来很大的存储成本，不适合大量订单场景。定时任务扫描，周期性扫描数据库，随着订单量增大，数据库扫描压力增大。Redis的Zset的key为订单类型：score为时间戳+超时时间 memeber为订单号，高并发时候会获取同一个订单号。</li>
</ul>
<h3 id="使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？"><a href="#使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？" class="headerlink" title="使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？"></a>使用RocketMQ延时队列处理超时订单，如果消息堆积（比如大量用户未支付），如何优化消费速度？</h3><ul>
<li>增加分区和消费者实例，调整消费线程数，批量消费减少IO</li>
</ul>
<h3 id="RocketMQ-只支持固定延迟级别（如1s-5s-10s），如何实现自定义延迟（如精确30分钟）？"><a href="#RocketMQ-只支持固定延迟级别（如1s-5s-10s），如何实现自定义延迟（如精确30分钟）？" class="headerlink" title="RocketMQ 只支持固定延迟级别（如1s, 5s, 10s），如何实现自定义延迟（如精确30分钟）？"></a>RocketMQ 只支持固定延迟级别（如1s, 5s, 10s），如何实现自定义延迟（如精确30分钟）？</h3><ul>
<li>第一种方案可以考虑，先用最合适的固定延迟级别，然后到期消费后，在消费端的逻辑做判断，如果没到时可以考虑先将消息存储，定时任务再触发去消费该消息，可能考虑消费者宕机消息丢失情况。第二种就在消费者端做判断，重新将消息发回RocketMQ，做延迟队列的组合</li>
</ul>
<h3 id="延时队列底层原理"><a href="#延时队列底层原理" class="headerlink" title="延时队列底层原理"></a>延时队列底层原理</h3><ul>
<li>根据延时级别将消息存储到内部定时Topic-&gt;时间轮算法：Broker启动，为每个延迟级别创建一个时间轮槽位，组成环形结构。每个槽位对应一个定时任务队列（消息）-&gt;消息进入定时主题时解析延时级别 计算存入目标槽位。broker启动后台线程池（驱动，消息到期检测，投递），每秒驱动时间轮遍历槽位消息重定向到目标Topic用于被消费</li>
</ul>
<h3 id="介绍一下项目的订单模型？"><a href="#介绍一下项目的订单模型？" class="headerlink" title="介绍一下项目的订单模型？"></a>介绍一下项目的订单模型？</h3><ul>
<li>首先订单表包括订单的基本信息订单ID，用户ID，总金额，订单状态，创建时间等。还有订单详情表，包括订单ID,收货地址，商品详情等。订单也关联实体有，例如用户，商品，库存，支付记录等。另外，订单从创建到结束包括多个状态，例如待支付，超时，已支付，已退款。</li>
</ul>
<h3 id="在大量订单情况下，有什么解决方案？"><a href="#在大量订单情况下，有什么解决方案？" class="headerlink" title="在大量订单情况下，有什么解决方案？"></a>在大量订单情况下，有什么解决方案？</h3><ul>
<li>在高并发请求的场景下，将数据库分片，分散请求的流量，分片键可以选择订单ID，用户ID或者按照创建时间。对于单表较大导致IO次数过多的情况下，考虑使用，按冷热字段分表例如订单基本信息表和详情表。或者根据订单id+用户id分表。分片算法在没有频繁变动分片数量时候可以用简单的哈希取模，或者维护一个映射表，在频繁变动的情况使用一致性哈希。</li>
</ul>
<h2 id="优惠券模块"><a href="#优惠券模块" class="headerlink" title="优惠券模块"></a>优惠券模块</h2><h3 id="讲讲优惠券抢券模块流程，和数据库表设置"><a href="#讲讲优惠券抢券模块流程，和数据库表设置" class="headerlink" title="讲讲优惠券抢券模块流程，和数据库表设置"></a>讲讲优惠券抢券模块流程，和数据库表设置</h3><ul>
<li>用户选择优惠券后下单，前端发送用户id和优惠券id，服务端进行幂等校验，使用Redis Set记录用户是否已经领取过优惠券（用户id和优惠券id），为了避免对数据库进行频繁写入造成性能瓶颈，扣除redis中的预热库存，使用RocktMQ进行异步批量提交，DB消费消息，更新用户优惠券表和优惠券库存表。</li>
<li>数据库表主要设计了三个表，一个是优惠券基本信息表，一个用户领取表，记录用户和优惠券的关系，一个是优惠券库存表记录优惠券库存</li>
</ul>
<h3 id="幂等性的实现方案"><a href="#幂等性的实现方案" class="headerlink" title="幂等性的实现方案"></a>幂等性的实现方案</h3><ul>
<li>set的key为券id，value为user id。命令SADD key member ，若成功添加证明无重复元素，返回1，若返回0则是有重复元素。</li>
<li>数据库层面：券id+user id作为唯一索引</li>
<li>用户进入订单确认页的时候生成一个token，并返回给客户端，客户端后续携带token，若存在token则第一次访问，执行服务后删除token</li>
</ul>
<h3 id="预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？"><a href="#预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？" class="headerlink" title="预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？"></a>预扣库存成功后，若系统崩溃导致未写入数据库，如何恢复数据一致性？</h3><ul>
<li>利用RocketMQ持久化来保证系统崩溃了也能被恢复，消费失败时尝试重试策略，到达重试次数移入死信队列，进行人工处理。为了避免不重复消费，可以给消息添加唯一标识符，消费时判断，或者在数据库中添加字段标记是否成功处理。如果只要求最终一致性，可以启用一个定时任务，检查redis中库存和数据库实际库存一致，做补偿。</li>
<li>如果要回滚redis，首先可以使用数据库事务+redis事务的方法，先开启数据库事务如果数据库更新成功，再提交redis事务，如果redis扣除成功则提交事务否则回滚数据库事务。第二点就是redis写入成功意味着redis IO是正常的，可以将redis扣除库存的日志写入redis中，如果数据库更新成功就删除日志，否则根据日志回滚。</li>
</ul>
<h3 id="为什么选择Lua脚本而不是Redis事务（MULTI-EXEC）？"><a href="#为什么选择Lua脚本而不是Redis事务（MULTI-EXEC）？" class="headerlink" title="为什么选择Lua脚本而不是Redis事务（MULTI&#x2F;EXEC）？"></a>为什么选择Lua脚本而不是Redis事务（MULTI&#x2F;EXEC）？</h3><ul>
<li>Lua脚本将几条命令封装为一条原子命令执行，期间不可中断。如果使用地是Redis事务，主要用的是Multi&#x2F;exec，在exec之前其他客户端也可以发送命令，导致事务失败。第二就是减少了网络传输地次数，lua脚本是一条命令只要一次传输，redis事务要多次传输</li>
</ul>
<h3 id="“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？"><a href="#“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？" class="headerlink" title="“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？"></a>“随机不重复轮询子库存”具体如何实现？如何避免不同用户请求集中在同一分片？如果某个分片库存提前耗尽，如何动态跳过该分片？</h3><ul>
<li>为了避免每次库存扣减都从第一个分片开始，造成单实例压力过大。维护一个分片ID的数组，和一个整型计数器。当有一个新的请求时，打乱分片id数组，使得每次请求分片按不同顺序分片扣除库存。可以用一个表记录每个分片剩余量，当剩余量为0时跳过。对比哈希取模去进行负载均衡的话，其扩展性比较差，在添加实例时，需要按新的数量取模，重新分布库存。</li>
</ul>
<h3 id="讲讲超卖产生的原因以及如何防止超卖？"><a href="#讲讲超卖产生的原因以及如何防止超卖？" class="headerlink" title="讲讲超卖产生的原因以及如何防止超卖？"></a>讲讲超卖产生的原因以及如何防止超卖？</h3><ul>
<li>超卖的主要原因是判断库存数量和扣除库存这两步不是原子的，当多个线程修改同一个优惠券库存时，由于同一个线程两次读数据不一致，导致库存多扣。有几种思路可以解决，如果是直接访问数据库去扣除库存，在单服务实例时，在业务层可以使用JVM锁例如Synchronized或者ReentransLock，如果是多服务实例时JVM锁失效，可以考虑使用redis分布式锁。在数据库层面，可以使用互斥锁，例如update语句或者for update，或者可以使用乐观锁的思想，通过CAS去保证并发安全。另外本项目采取的思路是，由于考虑到在抢券时并发激烈，先将库存预热到redis里，将判断库存和扣减库存两个命令写成lua脚本，利用redis命令执行是单线程的，将lua脚本作为一条命令放入redis执行，以保证判断库存和扣减库存是原子性的。 扣除完后将消息投递到消息队列中，数据库服务异步消费。这种方法既保证线程安全同时减轻数据库负担。</li>
</ul>
<h3 id="讲讲分布式锁"><a href="#讲讲分布式锁" class="headerlink" title="讲讲分布式锁"></a>讲讲分布式锁</h3><ul>
<li>使用setnx key value EX time 保证设置键和过期时间为原子性执行。防止线程A获取锁后实例挂了，没释放，此时又没设置过期时间。–如果在执行过程中，锁过期了，导致其他线程获得锁同时访问资源导致操作错误。所以使用锁续期，开启一个线程每个5秒查看锁是否存在，如果存在则继续续期为10s。当然如果，B已经获取了分布式锁，A有可能会误删锁，所以可以为每个线程上锁时生成一个唯一标识写入value中，在删除锁时先匹配标识，一致才可以删除，这个过程也需要原子性，所以也要通过lua脚本。—-在Redis主从一致环境下，如果主还未同步锁给从实例GG，此时会有AB线程都会获得锁的情况，导致资源被并行访问导致脏数据。可以使用RedLock算法，即线程锁时，需要将锁写入一定数量的从节点从保证上锁成功，以牺牲性能换取高可靠。</li>
</ul>
<h1 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h1><h3 id="介绍一下工作流程"><a href="#介绍一下工作流程" class="headerlink" title="介绍一下工作流程"></a>介绍一下工作流程</h3><ul>
<li>服务端先将接口服务的全限定名和IP地址+端口注册到注册中心，客户端通过接口名调用服务，动态代理拦截接口方法，根据服务接口的全限定名获取方法地址，底层基于TCP，添加版本类型，包类型，序列化类型，和数据长度作为包头，定义实现了序列化接口的RPC发送类，里面定义了调用的方法名和参数类型以及具体参数。将RPC发送类序列化后，根据地址传输到服务端。服务端解析包头，根据数据长度获取包长，根据包类型和序列化方式，反序列化获取需要调用的方法名，以及所用的参数。调用服务获得结果后，按同样的方法返回给客户端。</li>
</ul>
<h3 id="为什么选择Netty而不是传统BIO或直接使用Java-NIO？如何优化Netty的线程模型以支撑10万级QPS？"><a href="#为什么选择Netty而不是传统BIO或直接使用Java-NIO？如何优化Netty的线程模型以支撑10万级QPS？" class="headerlink" title="为什么选择Netty而不是传统BIO或直接使用Java NIO？如何优化Netty的线程模型以支撑10万级QPS？"></a>为什么选择Netty而不是传统BIO或直接使用Java NIO？如何优化Netty的线程模型以支撑10万级QPS？</h3><ul>
<li>首先它相比于传统的BIO，在进行IO连接的时候，使用的是事件驱动的方法，只用更少的线程去支撑海量的连接，避免资源耗尽。另外对比用JAVA NIO的话，java NIO需要自己去创建seletor，注册事件，netty封装了底层这些细节，提供更高层次的API</li>
</ul>
<h3 id="介绍BIO-NIO-JAVA-NIO"><a href="#介绍BIO-NIO-JAVA-NIO" class="headerlink" title="介绍BIO NIO JAVA NIO"></a>介绍BIO NIO JAVA NIO</h3><ul>
<li>BIO就说BlockingIO，也就是阻塞IO，也就是说服务端创建一个线程处理客户端的读写连接时，当数据还没到来，线程会被阻塞。随着连接数增多，也就是工作线程增多，大量线程的阻塞导致占用大量系统资源。而JAVA NIO则是New IO，本质上是使用了IO多路复用的方法处理多个连接。多路则是指多个连接，复用则是指用一个或者少量的线程去处理这些连接。具体来说，IO多路复用用三种机制，分别是（select，poll和epoll），对于select来说，对每个连接都维护一个文件描述符fd，将fd的事件例如连接、读、写就绪注册到select上，执行select的时候阻塞等待fd上事件的到来，内核态轮询fd事件到来时将修改标志位并返回fd的集合，用户态轮询所有fd，查询事件发生的fd进行处理，以实现单个线程监听多个连接的事件实现多路复用。select有个弊端就是监控的fd有限，poll则是通过动态数组存储fd以扩展可用的fd数量。而epoll则是将fd构成了一棵红黑树，当有事件来临时则，通过触发的方式将fd加入到一个双向链表中，用户只要进行一次系统调用则可获取触发事件的fd列表，不需要对所有fd进行轮询。</li>
</ul>
<h3 id="Reactor模型"><a href="#Reactor模型" class="headerlink" title="Reactor模型"></a>Reactor模型</h3><ul>
<li>处理一次IO为三部分：连接处理（注册事件–accept）、IO读写（Handle）、业务处理（Handle）—-单Reactor是指，连接、IO处理，业务处理都用同一个线程—一旦阻塞不能处理后续节点连接—-6.0之前redis是这个模型。<strong>多线程 Reactor 模型</strong>：主线程处理连接，以及读写，子线程池（此时非阻塞体现在如果channel无读事件，会立刻返回以实现线程池的线程复用）处理业务，发挥多核优势，但IO读写还是用一个线程导致其他读写阻塞。主从Reactor多线程模型是指，连接和IO分别用不同线程处理，主为处理连接注册事件（accept），（线程池）创建线程处理IO读写，业务处理时用多个线程（线程池）。</li>
</ul>
<h3 id="Netty整体工作机制"><a href="#Netty整体工作机制" class="headerlink" title="Netty整体工作机制"></a>Netty整体工作机制</h3><ul>
<li>网络通信层 客户端服务端启动，监听指定端口—事件调度器主从多线程模型 Boss，Worker—服务编排层，即work处理使用处理链（业务是否多线程自己处理）</li>
</ul>
<h3 id="Netty性能好在哪里？"><a href="#Netty性能好在哪里？" class="headerlink" title="Netty性能好在哪里？"></a>Netty性能好在哪里？</h3><ul>
<li>IO连接使用多Reactor模型、使用零拷贝机制，即通过api直接读写直接内存，避免拷贝进堆内存，提供多种序列化方式，包括性能告得protobuf</li>
</ul>
<h3 id="你是如何解决粘包拆包的？Netty是如何实现的"><a href="#你是如何解决粘包拆包的？Netty是如何实现的" class="headerlink" title="你是如何解决粘包拆包的？Netty是如何实现的"></a>你是如何解决粘包拆包的？Netty是如何实现的</h3><ul>
<li>因为我底层用的是TCP，TCP是基于字节流的，而且保证有序到达。所以我通过在包头前面添加一个包长字段，解析出长度后，每次获取包长的字节数，以解决粘包拆包问题。Netty是封装了3种解决粘包的方案，一种是固定消息长度，每次收发固定长度的消息。第二种是以特定分隔符结尾，第三种应该是跟我这个思想一样，标明固定长度。</li>
</ul>
<h3 id="为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？"><a href="#为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？" class="headerlink" title="为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？"></a>为什么需要支持多种序列化方式？讲讲序列化和反序列化？如何设计一个可扩展的序列化框架？</h3><ul>
<li>一个是兼容不同的编程语言和平台，二是根据需求来指定序列化方式，例如JSON便于阅读，适用于开发阶段。Protobuf是基于二进制的，性能更好。首先在抽象层可以定义一个通用的接口，包括序列化方法和反序列化方法。其次可以使用工厂模式来获取序列化编码器，注册的时候直接在工厂内部将序列化代码和编码器放入一个Map中，每次使用序列化代码调用工厂即可。</li>
</ul>
<h3 id="Protobuf和JSON的性能差异有多大？介绍一下Protobuf"><a href="#Protobuf和JSON的性能差异有多大？介绍一下Protobuf" class="headerlink" title="Protobuf和JSON的性能差异有多大？介绍一下Protobuf"></a>Protobuf和JSON的性能差异有多大？介绍一下Protobuf</h3><ul>
<li>Protobuf使用二进制格式而不是文本格式，减少了传输的体积，大概快3-10倍。通过定义<code>.proto</code>文件来描述数据结构，Protobuf能够自动生成对应多种编程语言的源代码。在反序列化的时候，根据<code>.proto</code>文件指定的结构还原对象。</li>
</ul>
<h3 id="为什么选择JDK动态代理而非CGLIB？"><a href="#为什么选择JDK动态代理而非CGLIB？" class="headerlink" title="为什么选择JDK动态代理而非CGLIB？"></a>为什么选择JDK动态代理而非CGLIB？</h3><ul>
<li>客户端使用RPC调用服务的时候，是调用了服务接口，而JDK动态代理适用实现接口的类，在这个场景下性能比CGLIB好，因为前者通过反射调用目标方法开销小，CGLIB通过字节码操作技术生成目标类的一个子类来实现代理功能。</li>
</ul>
<h3 id="如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？"><a href="#如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？" class="headerlink" title="如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？"></a>如何保证服务注册的实时性？Nacos如何避免服务列表的脏读？对比Zookeeper，Nacos的优劣是什么？</h3><ul>
<li>主要用两点，一个是心跳机制：客户端定期向服务注册中心发送心跳包，以表明其仍然存活。如果服务中心一段时间没收到，则认为服务不可用，从列表删除。第二个是重试机制，在服务调用失败的时候，能够快速选择其他好的服务或者重试。Nacos内部实现了高效的缓存一致性协议，确保客户端缓存和服务端的数据一致性。另外Nacos主动推送自己的最新服务给客户端。Zookeeper强调强一致性，适用强一致性场景，牺牲了性能。Nacos更专注于服务注册，提供合适的API，例如服务注册，健康检查等功能。</li>
</ul>
<h3 id="如何设计一个注册中心？"><a href="#如何设计一个注册中心？" class="headerlink" title="如何设计一个注册中心？"></a>如何设计一个注册中心？</h3><ul>
<li>服务注册与发现（Map），健康检查(心跳机制)，负载均衡，高可用（集群，一致性算法），可拓展</li>
</ul>
<h3 id="如果某个服务节点响应时间突然变长，如何动态调整权重？"><a href="#如果某个服务节点响应时间突然变长，如何动态调整权重？" class="headerlink" title="如果某个服务节点响应时间突然变长，如何动态调整权重？"></a>如果某个服务节点响应时间突然变长，如何动态调整权重？</h3><ul>
<li>根据ping的响应时间调整权重。</li>
</ul>
<h3 id="讲讲Nacos的Raft"><a href="#讲讲Nacos的Raft" class="headerlink" title="讲讲Nacos的Raft"></a>讲讲Nacos的Raft</h3><ul>
<li>raft有三种角色，一个是Leader，follower和Condidate，首先是选举，Leader宕机后或到达任期之后，follower按一定随机时间生成Condiate，通过请求投票，当获取超半数之后升级为leader。主从是读写分离，为了保证一致性，写操作统一写入leader，leader同步日志到follower，超过一定数量后给客户端响应。</li>
</ul>
<h3 id="如何实现RPC调用超时和重试机制？"><a href="#如何实现RPC调用超时和重试机制？" class="headerlink" title="如何实现RPC调用超时和重试机制？"></a>如何实现RPC调用超时和重试机制？</h3><ul>
<li>调用时设计超时时间，超时指数退避重试。幂等性，唯一标识符。</li>
</ul>
<h3 id="如果有个系统要应用到你的RPC框架，需要做哪些事情？"><a href="#如果有个系统要应用到你的RPC框架，需要做哪些事情？" class="headerlink" title="如果有个系统要应用到你的RPC框架，需要做哪些事情？"></a>如果有个系统要应用到你的RPC框架，需要做哪些事情？</h3><h3 id="性能瓶颈在哪里？"><a href="#性能瓶颈在哪里？" class="headerlink" title="性能瓶颈在哪里？"></a>性能瓶颈在哪里？</h3><ul>
<li>首先是网络IO–可以通过使用合适的序列化方式例如protobuf减少数据量，或者批量调用减少网络次数。第二个是序列化，选用高效的序列化方法也很重要。另外在客户端，当频繁调用服务时意味着要频繁到注册中心请求服务成为性能瓶颈，可以使用缓存来提升性能。第三点是服务端处理大量RPC请求时也可能成为瓶颈，一个是服务端处理业务时使用线程池处理，第二点可以使用负载均衡。</li>
</ul>
<h1 id="问题排查及解决方案"><a href="#问题排查及解决方案" class="headerlink" title="问题排查及解决方案"></a>问题排查及解决方案</h1><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><p><strong>定位</strong></p>
<ul>
<li>开启慢日志</li>
<li>Explain（模拟优化器执行）<ul>
<li>key：使用的索引</li>
<li>type: system（表中只有一行数据) ，const(只有一行索引匹配)，eq_ref（主键或唯一索引的等值连接），ref（非主键非唯一索引），range（索引范围），index（全表索引），all（全表扫描）</li>
</ul>
</li>
</ul>
<p><strong>优化角度</strong></p>
<ul>
<li>数据量<ul>
<li>数据量越大IO次数越多</li>
</ul>
</li>
<li>取数据方式<ul>
<li>磁盘还是缓存</li>
<li>是否能结合谓词条件命中全局索引</li>
</ul>
</li>
<li>数据加工方式<ul>
<li>排序、子查询、聚合、关联等取到临时表中，对数据加工</li>
<li>合适的join方式</li>
</ul>
</li>
</ul>
<p><strong>优化思路</strong></p>
<ul>
<li><p>减少数据扫描</p>
<ul>
<li><p>数据分页优化</p>
<blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">select * from table_demo <span class="type">where</span> <span class="variable">type</span> <span class="operator">=</span> ?  limit A,B; </span><br><span class="line">---limit+offset，每次查询B条数据都要扫描跳过前A-<span class="number">1</span>条数据</span><br><span class="line"></span><br><span class="line">lastId = <span class="number">0</span> or <span class="title function_">min</span><span class="params">(id)</span></span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">select * from table_demo <span class="type">where</span> <span class="variable">type</span> <span class="operator">=</span> ? and id &gt;&#123;#lastId&#125;  limit ?;</span><br><span class="line">lastId = max(id)</span><br><span class="line">&#125; <span class="keyword">while</span> (isNotEmpty)</span><br><span class="line">---记录偏移ID，新页直接定位到上一次的<span class="type">ID</span></span><br><span class="line"></span><br><span class="line"><span class="variable">minId</span> <span class="operator">=</span> min(id) maxId = max(id)</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> minId; i&lt;= maxId; i+=pageSize)&#123;</span><br><span class="line">select * from table_demo <span class="type">where</span> <span class="variable">type</span> <span class="operator">=</span> ? and id between i and i+ pageSize;</span><br><span class="line">&#125;</span><br><span class="line">--- between and，分段查询 虽然可以减少扫描遍历情况，但是不适用于查询的键分布不均的情况，多了一些不必要的查询</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>Groud By分组优化</p>
<blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select job , avg(sal) from table_demo <span class="type">where</span>  <span class="variable">job</span> <span class="operator">=</span> ‘manager<span class="string">&#x27; group by job</span></span><br><span class="line"><span class="string">先过滤后分组</span></span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>范围查询</p>
<blockquote>
<p>单键索引: 查询到主键索引时，先排序后回表Multi Range Read(MRR)），可以减少IO次数（一个页中有多个连续行）</p>
<p>联合索引：Mysql5.6+，等式放范围查询的右边会通过索引下推过滤回表的主键数，当然：等值最左匹配才是优解</p>
</blockquote>
</li>
<li><p>Order By</p>
<blockquote>
<p>索引覆盖排序 ：order前建立索引时已经排好序</p>
</blockquote>
</li>
<li><p>业务划分</p>
<blockquote>
<p>date &#x3D; now; minDate &#x3D; now - 10 days<br>while(date &gt; minDate) {<br>select * from order where order_date&#x3D;{<em>#date} and status&#x3D;’S’ and update_time &lt; now-5min limit 500</em>  date &#x3D; data + 1}</p>
<p>对比: 快在可以对order_date索引（status如果太均匀失效了），避免一次性读太大量的表进内存</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from order where status=<span class="string">&#x27;S&#x27;</span> and update_time &lt; now-5min  limit <span class="number">500</span></span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
</li>
<li><p>数据库结构优化</p>
<ul>
<li>范式优化：消除冗余</li>
<li>反范式优化：适当加冗余-避免join操作（有时候不满足第三范式也能提升速度）</li>
<li>按物理结构拆分表，避免全表扫描（例如按日期）</li>
</ul>
</li>
<li><p>SQL语句优化</p>
<ul>
<li>区分 in 和 exists（in先执行子查询后逐行判断-适合内表小的情况（子查询返回的结果少），后者遍历外表逐行执行子查询，遇到匹配项停止减少扫描。因为每次子查询需要开销，在少量数据的时候还是用in）</li>
<li>尽量避免使用子查询-&gt;join&#x2F;反范式优化</li>
</ul>
</li>
<li><p>大表优化</p>
<ul>
<li>分库分表</li>
<li>读写分离（主从复制）</li>
<li>定期归档（历史数据移除，减少主表大小）</li>
</ul>
</li>
</ul>
<h2 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h2><h2 id="接口超时"><a href="#接口超时" class="headerlink" title="接口超时"></a>接口超时</h2><h2 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h2><h1 id="海量数据处理"><a href="#海量数据处理" class="headerlink" title="海量数据处理"></a>海量数据处理</h1><h2 id="高频统计类"><a href="#高频统计类" class="headerlink" title="高频统计类"></a>高频统计类</h2><h3 id="TOP-K问题-次数出现最多元素"><a href="#TOP-K问题-次数出现最多元素" class="headerlink" title="TOP K问题 &#x2F; 次数出现最多元素"></a>TOP K问题 &#x2F; 次数出现最多元素</h3><ul>
<li>方法一：首先将大文件转成小文件：具体来说，可用使用Hash元素取模M分成M个小文件，目的是将相同的元素放在同一文件中。然后，将小文件加载进内存中用HashMap记录元素出现次数，遍历HashMap构造有100个节点的小根堆。接下来就是遍历所有文件，重复HashMap记录次数，然后将元素次数和小根堆堆顶元素比较，若大于其则交换重构堆。—-该方法不足之处在于，若大量元素都相似，容易导致生成的小文件过大，大于内存。</li>
<li>方法二：首先先对文件里的字符串排序，保证相同的字符串连续。具体来说：大文件顺序按固定大小切分为子文件，子文件分别进内存后对字符串排序。使用多路归并排序，即初始化M个结点的最小堆，每个结点代表各子文件输入流的第一个元素，从最小堆中取出最小元素，并将其写入输出文件，同时堆顶元素对应文件读入下一个元素放入堆中，重复过程直至大文件有序。 然后，维护一个K结点的最小堆，节点为元素对应出现次数，遇到新元素则统计完元素数量后元堆顶元素比较，若大于则取出堆顶元素并加入。</li>
</ul>
<h2 id="存在性判断与去重"><a href="#存在性判断与去重" class="headerlink" title="存在性判断与去重"></a>存在性判断与去重</h2><h3 id="判断元素存在"><a href="#判断元素存在" class="headerlink" title="判断元素存在"></a>判断元素存在</h3><ul>
<li>方法一：排序后，遍历</li>
<li>方法二：位图法：40亿个整数可以用2的32次方表示，也就是512MB。初始化个数组位为0，若数字存在对应位置置1，遍历位图。</li>
</ul>
<h3 id="找出不重复元素"><a href="#找出不重复元素" class="headerlink" title="找出不重复元素"></a>找出不重复元素</h3><ul>
<li>方法一：排序后，遍历</li>
<li>方法二：位图法：40亿个整数可以用2的32次方表示，2bit作为信息为 00为不存在 01为1个元素 10为重复元素，2*512MB&#x3D;1GB</li>
</ul>
<h2 id="交集与合并的问题"><a href="#交集与合并的问题" class="headerlink" title="交集与合并的问题"></a>交集与合并的问题</h2><h3 id="大文件交集"><a href="#大文件交集" class="headerlink" title="大文件交集"></a>大文件交集</h3><ul>
<li>两个大文件用相同的哈希函数和取模基数，保证相同的URL都在相同序号的子文件中。只要比较子文件的内容即可</li>
</ul>
<h2 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h2><ul>
<li>从最高位开始划分数据，进而到次高进制，重复过程直到定位到中位数所在区间并且满足内存空间大小</li>
</ul>

    </div>

    
        <hr class="fhr">
        <div id="vcomments"></div>
    
</div>
    <div class="footer" id="footer">
    <p><h4>版权所有 © 2020 | 作者: 食芒果冰 | 主题 By <a class="theme-author" target="_blank" rel="noopener" href="https://github.com/Xunzhuo/hexo-theme-coder" style="font-size:14px; color: #969696">Coder</a></h4>
    
    <label class="el-switch el-switch-blue el-switch-sm" style="vertical-align: sub;">
        <input type="checkbox" name="switch" id="update_style">
        <span class="el-switch-style"></span>
    </label>

    <!--         <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1278548644'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D1278548644%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
    </script> -->
</p>
</div>

<input type="hidden" id="web_style" value="black">
<input type="hidden" id="valine_appid" value="">
<input type="hidden" id="valine_appKey" value="">

<script src="/libs/jquery.min.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>

<script src='//cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>

<script src="/js/js.js"></script>

<style type="text/css">
.v * {
color: #698fca;
}
.v .vlist .vcard .vhead .vsys {
color: #3a3e4a;
}
.v .vlist .vcard .vh .vmeta .vat {
color: #638fd5;
}
.v .vlist .vcard .vhead .vnick {
color: #6ba1ff;
}
.v a {
color: #8696b1;
}
.v .vlist .vcard .vhead .vnick:hover {
color: #669bfc;
}
</style>
    <script type="text/javascript" color="173,174,173" opacity='1' zIndex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
</body>
</html>
